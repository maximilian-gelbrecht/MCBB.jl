<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Basic Usage · MCBB</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>MCBB</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><span class="toctext">Manual</span><ul><li class="current"><a class="toctext" href>Basic Usage</a><ul class="internal"><li><a class="toctext" href="#Logistic-Map-1">Logistic Map</a></li><li><a class="toctext" href="#Kuramoto-Network-1">Kuramoto Network</a></li><li><a class="toctext" href="#Solution-Object-1">Solution Object</a></li><li><a class="toctext" href="#Distance-Matrix/Metric-1">Distance Matrix/Metric</a></li><li><a class="toctext" href="#Clustering-1">Clustering</a></li><li><a class="toctext" href="#How-to-define-your-own-systems.-1">How-to define your own systems.</a></li><li><a class="toctext" href="#Saving-and-Loading-1">Saving &amp; Loading</a></li><li><a class="toctext" href="#Tips-and-Tricks-1">Tips &amp; Tricks</a></li></ul></li><li><a class="toctext" href="../introspective_features/">Introspective Features</a></li><li><a class="toctext" href="../hpc/">Running it on a HPC</a></li><li><a class="toctext" href="../multidim_parameters/">Multidimensional Parameter Setups</a></li><li><a class="toctext" href="../custom_problems/">Custom Problem</a></li><li><a class="toctext" href="../continuation/">Continuation</a></li></ul></li><li><span class="toctext">Reference</span><ul><li><a class="toctext" href="../ref/problem_types/">Problem Types</a></li><li><a class="toctext" href="../ref/parameter_var/">ParameterVar</a></li><li><a class="toctext" href="../ref/evaluation_funcs/">Evaluation Functions</a></li><li><a class="toctext" href="../ref/clustering_funcs/">Clustering Functions</a></li><li><a class="toctext" href="../ref/continuation/">Continuation</a></li><li><a class="toctext" href="../ref/systems/">Systems</a></li><li><a class="toctext" href="../ref/custom_problem/">Custom Problems</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Manual</li><li><a href>Basic Usage</a></li></ul><a class="edit-page" href="https://github.com/maximilian-gelbrecht/MCBB.jl/blob/master/docs/src/basic_usage.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Basic Usage</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Basic-Usage-1" href="#Basic-Usage-1">Basic Usage</a></h1><p>In the following we will show how the library works on two example, a logistic map and a first order Kuramoto network. All important routines and functions also have docstrings that can be either viewed in the reference here in this documentation or by using Julia&#39;s regular help interface (first typing &quot;?&quot; and then the name of the function).</p><p>First, we import the library and all other packages that we need to set up the systems.</p><pre><code class="language-julia">using MCBB
using LightGraphs
using Clustering
using DifferentialEquations
using Distributions
using StatsBase
using Plots
using Random
import PyPlot
Random.Random.seed!(13423);</code></pre><h2><a class="nav-anchor" id="Logistic-Map-1" href="#Logistic-Map-1">Logistic Map</a></h2><p>The logistic map <span>$x_{n+1} = r x_{n}(1 - x_{n})$</span> is one of the most well known and studied chaotic systems. Even though this library is tailored towards higher dimensional and multistable system, we can study the logistic map with it as a first example as well.</p><p>First, we set up how the parameter, <span>$r$</span> and the initial conditions should be varied. The function generating the ICs and parameters need have either <code>()-&gt;new_value::Number</code> or <code>(i_run)-&gt;new_value::Number</code> signature.</p><pre><code class="language-julia">rdist = Uniform(2.5,4);
icdist = Uniform(0.1,0.99);
r = ()-&gt;rand(rdist);
ic_ranges = ()-&gt;rand(icdist);</code></pre><p>There are also other ways to setup the initial conditions. You can define a function that returns an array for all system dimensions for multidimensional systems or provide arrays with the values directly. See <a href="../ref/problem_types/#MCBB.DEMCBBProblem"><code>DEMCBBProblem</code></a> for more infos.   Then, we set up how many initial conditons / parameter points we want to generate and solve</p><pre><code class="language-julia">N_ic = 5000;</code></pre><p>The parameters of our systems are supposed to be structs whose supertype is <code>DEParameters</code>, e.g. <code>struct my_par &lt;: DEParameters end</code>. In this case, the logistic map and its parameters are already pre-made in the library:</p><pre><code class="language-julia">pars = logistic_parameters(r());
par_var = (:r,r);</code></pre><p>The tuple <code>par_var</code> contains the name of the parameter field to be changed as a symbol and the function how it should be changed. This tuple will be automatically converted to a <a href="../ref/parameter_var/#MCBB.ParameterVar"><code>ParameterVar</code></a> which also could have been constructed directly. This can be needed for more complicated setups.</p><p>Next, we set up the base DifferentialEquations problem (if you are interested in problems that can&#39;t be solved with DifferentialEquations, see <a href="../ref/custom_problem/#MCBB.CustomMCBBProblem"><code>CustomMCBBProblem</code></a>). As mentioned, the logistic map is already one of the pre-made systems, thus</p><pre><code class="language-julia">dp = DiscreteProblem(logistic, [ic_ranges()], (0.,1000.), pars);</code></pre><p>We are only interested in solutions after 80% of the integration time</p><pre><code class="language-julia">tail_frac = 0.8;</code></pre><p>and can use the pre-made <code>eval_ode_run</code> for analyzing the solutions of each Differential Equation (see <a href="../ref/evaluation_funcs/#MCBB.eval_ode_run"><code>eval_ode_run</code></a> for more information). This <code>eval_ode_run</code> will track the mean, std and Kullback-Leibler divergence of the solutions. Thus we can finally setup the <a href="../ref/problem_types/#MCBB.DEMCBBProblem"><code>DEMCBBProblem</code></a> with</p><pre><code class="language-julia">log_emcp = DEMCBBProblem(dp, ic_ranges, N_ic, pars, (:r,r), eval_ode_run, tail_frac);</code></pre><p>and solve it</p><pre><code class="language-julia">log_sol = solve(log_emcp);</code></pre><p>Subsequently, we calculate the distance matrix and cluster the results</p><pre><code class="language-julia">D = distance_matrix(log_sol, log_emcp, [1,0.75,0.5,1.]);
</code></pre><p>In order to determine the <span>$\epsilon$</span> parameter of DBSCAN we suggest one of three possibilities:</p><ul><li>k-dist graph to the 4-th Neareast neighbour: <a href="../ref/clustering_funcs/#MCBB.k_dist"><code>k_dist</code></a></li><li>cumulative KNN distance: <a href="../ref/clustering_funcs/#MCBB.KNN_dist"><code>KNN_dist</code></a> and <a href="../ref/clustering_funcs/#MCBB.KNN_dist_relative"><code>KNN_dist_relative</code></a></li><li>response analysis by continuation of the integration (more complicated and computationally intensive): <a href="../ref/evaluation_funcs/#MCBB.eval_ode_run"><code>eval_ode_run</code></a></li></ul><p>For many systems we tried, we found that all three methods yield similar results. In this case we take the median of the <span>$0.5\\%$</span> of all members nearest neighbour (in this case 25-NN).</p><pre><code class="language-julia">median(KNN_dist_relative(D))
&gt; 0.06565762359625632</code></pre><pre><code class="language-julia">db_eps = 0.04
db_res = dbscan(D,db_eps,4)
cluster_members = cluster_membership(log_emcp,db_res,0.005,0.001);
plot(cluster_members)</code></pre><p><img src="../img/logmap_member.png" alt="Logistic Map Membership Diagram"/></p><p>For more details, see <a href="../ref/problem_types/#MCBB.DEMCBBProblem"><code>DEMCBBProblem</code></a> and the other references linked in this section.</p><h2><a class="nav-anchor" id="Kuramoto-Network-1" href="#Kuramoto-Network-1">Kuramoto Network</a></h2><p>Next, we will investigate the onset of synchronization in system of first order Kuramoto oscillators on an Erdos-Renyi random network. We set up the initial conditions and parameters similar to the first example:</p><pre><code class="language-julia">N = 20
K = 0.5
nd = Normal(0.5, 0.1)
w_i_par = rand(nd,N) # eigenfrequencies

net = erdos_renyi(N, 0.2)
A = adjacency_matrix(net)

ic = zeros(N)
ic_dist = Uniform(-pi,pi)
kdist = Uniform(0,5)
ic_ranges = ()-&gt;rand(ic_dist)
N_ics = 5000
K_range = ()-&gt;rand(kdist)
pars = kuramoto_network_parameters(K, w_i_par, N, A)

rp = ODEProblem(kuramoto_network, ic, (0.,1000.), pars)</code></pre><p>In this case we want to have another evaluation function. We don&#39;t need the Kullback-Leibler divergence, but we are interested in the global order parameter as the system to compare it to our results.</p><pre><code class="language-julia">function k_order_parameter(u::AbstractArray)
    uend = u[:,end]
    N = length(uend)
    1. /N*sqrt((sum(sin.(uend)))^2+(sum(cos.(uend)))^2)
end

function eval_ode_run_kura(sol, i)
    N_dim = length(sol.prob.u0)
    state_filter = collect(1:N_dim)
    eval_funcs = [mean, std]
    matrix_eval_funcs = []
    global_eval_funcs = [k_order_parameter]
    eval_ode_run(sol, i, state_filter, eval_funcs, matrix_eval_funcs, global_eval_funcs, cyclic_setback=true)
end</code></pre><p>It is also possible to track measures that return matrices or arrays of different size from the 1-d length-<code>N</code> arrays, like cross-correlation or covariance with the <code>matrix_eval_funcs</code> keyword. See <a href="../ref/evaluation_funcs/#MCBB.eval_ode_run"><code>eval_ode_run</code></a> for a detailed reference.</p><p>We set up the <code>DEMCBBProblem</code> again with</p><pre><code class="language-julia">tail_frac = 0.9  
ko_mcp = DEMCBBProblem(rp, ic_ranges, N_ics, pars, (:K, K_range), eval_ode_run_kura, tail_frac)
kosol = solve(ko_mcp)</code></pre><p>and solve and analyze it. In this case we set the weight of the order parameter to zero as we only want to have it as a comparison for our results.</p><pre><code class="language-julia">D_k = distance_matrix(kosol, ko_mcp, [1.,0.5,0,1.], histograms=true, k_bin=2); # no weight on the order_parameter
db_eps = 1.15 # we found that value by scanning manually
db_res = dbscan(D_k,db_eps,20)
cluster_members = cluster_membership(ko_mcp,db_res,0.1,0.025);
plot(cluster_members)</code></pre><p><img src="../img/kuramoto_member.png" alt="Kuramoto Membership Diagram"/></p><p>In this plot we see the onset of synchronization clearly as three distinctive clusters. We can compare this to the order parameter that we calculated:</p><pre><code class="language-julia">plot(parameter(ko_mcp),get_measure(kosol,3), xlabel=&quot;Coupling K&quot;, ylabel=&quot;Order Parameter R&quot;)</code></pre><p><img src="../img/output_6_0.png" alt="Kuramoto Order Parameter"/></p><p>As we see the cluster membership diagram really shows the onset of the synchronization.</p><h2><a class="nav-anchor" id="Solution-Object-1" href="#Solution-Object-1">Solution Object</a></h2><p>The solution object stores all the measures and some other information. <a href="@ref"><code>Introspective Features</code></a> in this manual goes into some more detail about it, but it is important to note that every of the measures are ordered in the following way:     * first: all per dimension measures in the same order as in the <code>eval_funcs</code> array (default: 1: mean, 2: SD, 3: KL-Div)     * then: all matrix measures     * then: all global measures     * optional: for routines that also incorporate the parameters, they are last in order. This order plays a role for all routines that work with one of the measures.</p><h2><a class="nav-anchor" id="Distance-Matrix/Metric-1" href="#Distance-Matrix/Metric-1">Distance Matrix/Metric</a></h2><p>The distance matrix calculation is one of these cases. When we assign the weights in the call to distance matrix, we have to adhere to this ordering. For the example above <code>[1.,0.75,0.,1.]</code> thus means: weight 1. on mean, 0.75 on SD, 0. on KL-Div and 1. on the parameter. The clustering is based on the distance matrix. Its calculation is performed with <a href="@ref">&#39;distance_matrix&#39;</a>. Naturally they are many ways how to define a distance matrix between the solutions. They are two main different variants in the library so far</p><ul><li>Directly compute the difference between the individual values of the measures with a suitable norm. This is the default option (with an L1-norm used)</li><li>For each measure first compute a histogram or empirical CDF for each run and compare these with each other. For this purpose the keyword <code>histograms=true</code> needs to be set. This is recommended when investigating systems with many (more or less) identical subparts such as oscillator networks and the specific position/number of a single oscillator is not important. The default measure to compare the histograms is the 1-Wasserstein distance.</li></ul><p>The distance functions return elements of type <a href="../ref/clustering_funcs/#MCBB.DistanceMatrix"><code>DistanceMatrix</code></a> or <a href="../ref/clustering_funcs/#MCBB.DistanceMatrixHist"><code>DistanceMatrixHist</code></a>. They behave just like regular arrays (and are in fact subtypes of <code>AbstractArray</code>) but also hold additional information about how the distance was computed. This can be espacially useful when using the histogram method.</p><h2><a class="nav-anchor" id="Clustering-1" href="#Clustering-1">Clustering</a></h2><p>So far, we used mainly DBSCAN for the clustering. In principal, one can also use other clustering algorithms though. DBSCAN also returns a &quot;Noise Cluster&quot;/Outlier. In the standard julia implemenation this is Cluster &quot;0&quot;, here for all routines the Outliers are Cluster &quot;1&quot; and all other clusters have the following ascending numbers.</p><h2><a class="nav-anchor" id="How-to-define-your-own-systems.-1" href="#How-to-define-your-own-systems.-1">How-to define your own systems.</a></h2><h3><a class="nav-anchor" id="System-Functions-1" href="#System-Functions-1">System Functions</a></h3><p>The system function follow the notation of DifferentialEquations.jl and should thus have arguments <code>(du,u,p,t)</code> that are changed inplace. For example a Roessler system can be definded with:  </p><pre><code class="language-julia">function roessler!(dx,x,p::roessler_pars,t)
  dx[1] = - x[2] - x[3]
  dx[2] = x[1] + p.a*x[2]
  dx[3] = p.b + (x[1] - p.c)*x[3]
end</code></pre><p>For more information also see the documentation of DifferentialEquations.jl. In case one wants to work with systems that can&#39;t be solved with DifferentialEquations.jl, one has to use <a href="../ref/custom_problem/#MCBB.CustomMCBBProblem"><code>CustomMCBBProblem</code></a>.</p><h3><a class="nav-anchor" id="Parameters-1" href="#Parameters-1">Parameters</a></h3><p>All parameters have to have <a href="../ref/systems/#MCBB.DEParameters"><code>DEParameters</code></a> as a supertype to work. Thus, for the Roessler example</p><pre><code class="language-julia">struct roessler_pars &lt;: DEParameters
  a::Number
  b::Number
  c::Number
end</code></pre><p>works as the parameter type. See <a href="../ref/systems/#MCBB.DEParameters"><code>DEParameters</code></a> and subsequent doc strings for a list of all pre-made functions and parameters.</p><h3><a class="nav-anchor" id="Varying-hidden/background-parameters-1" href="#Varying-hidden/background-parameters-1">Varying hidden/background parameters</a></h3><p>It is also possible to investigate setups that have many hidden/background parameters and one/two control parameters. The hidden/background parameters are then treated similar to initial conditions and are randomly generated for each control parameter. See <a href="@ref"><code>HiddenParameterVar</code></a> and <a href="../ref/problem_types/#MCBB.DEMCBBProblem"><code>DEMCBBProblem</code></a> for more infos.</p><h2><a class="nav-anchor" id="Saving-and-Loading-1" href="#Saving-and-Loading-1">Saving &amp; Loading</a></h2><p><code>BSON</code> and <code>JLD2</code> provide easy ways to save and load problem and solutions objects. However sometimes they can be a bit errorprone. If one encounters these kind of errors while loading saved JLD objects, one can also used the <a href="@ref"><code>save</code></a>, <a href="@ref"><code>load_prob</code></a> and <a href="@ref"><code>load_sol</code></a> routines.</p><h2><a class="nav-anchor" id="Tips-and-Tricks-1" href="#Tips-and-Tricks-1">Tips &amp; Tricks</a></h2><p>The method relies on random sampling, if you want to share scripts or notebooks and reliably get the same results, you should use a constant seed for the RNG with</p><pre><code class="language-julia">using Random
Random.seed!(23124);</code></pre><p>This is primarily needed because the ordering of the clusters can change for every run through the script.</p><p>In the next section, we will show how these results can be further analyzed.</p><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../introspective_features/"><span class="direction">Next</span><span class="title">Introspective Features</span></a></footer></article></body></html>
