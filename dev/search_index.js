var documenterSearchIndex = {"docs":
[{"location":"ref/bbclustering/#BBlustering-1","page":"BBlustering","title":"BBlustering","text":"","category":"section"},{"location":"ref/bbclustering/#","page":"BBlustering","title":"BBlustering","text":"bbcluster\nMCBB.BBClusterResult","category":"page"},{"location":"ref/bbclustering/#MCBB.bbcluster","page":"BBlustering","title":"MCBB.bbcluster","text":"bbcluster(D::AbstractDistanceMatrix, dplus::AbstractVector{T}, dminus::AbstractVector{T}, pars::AbstractVector{T}, p_eps::T, minpts::Int; k::S=1.5, par_distance_func::Union{Function, Nothing}=nothing) where {T,S}<:Real\n\nPerforms the BBClustering, a modified DBSCAN clustering adjusted for Basin Bifurcation Analysis\n\nInputs:\n\nD: Distance Matrix (NxN)\ndplus: Response of Distance Measure at p+\\delta p\ndminus: Response of Distance Measure at p-\\delta p\npars: Parameter vector\ndelta_p: Used to estimate response dplus and dminus\np_eps: Epsilon Parameter, only points with parameters closer than p_eps are connected.\nminpts: Minimum number of points for a cluster, otherwise outlier\nk: Paramater for the clustering, should be 1 < k < 2\npar_distance_func: Distance function for parameters, check: par_distance_func(pars[i],pars[j]) < p_eps\nbbcluster(D::AbstractArray, prob::MCBBProblem, sol::MCBBSol, deltap::T; peps::Union{Nothing,T}=nothing, minpts::Int=1, k::Number=1.5, pardistancefunc::Union{Function,Nothing}=nothing) where T<:Real\n\nConvenience wrapper of the above defined function with 'MCBBProblem' and 'MCBBSol' as inputs. Default value for p_eps is five times the mean parameter difference.\n\n\n\n\n\n","category":"function"},{"location":"ref/bbclustering/#MCBB.BBClusterResult","page":"BBlustering","title":"MCBB.BBClusterResult","text":"BBClusterResult <: ClusteringResult\n\nContains the solutions of the bbcluster. Has the fields  seeds, assignments and counts. \n\n\n\n\n\n","category":"type"},{"location":"ref/clustering_funcs/#Further-Evalution-and-Clustering-Functions-1","page":"Clustering Functions","title":"Further Evalution and Clustering Functions","text":"","category":"section"},{"location":"ref/clustering_funcs/#","page":"Clustering Functions","title":"Clustering Functions","text":"distance_matrix\nMCBB.distance_matrix_mmap\nMCBB.compute_distance\nMCBB.distance_matrix_sparse\nAbstractDistanceMatrix\nDistanceMatrix\nDistanceMatrixHist\nMCBB.metadata!(dm::AbstractDistanceMatrix)\nwasserstein_histogram_distance\necdf_hist\ncluster_distance\ncluster_means(sol::myMCSol, clusters::DbscanResult)\ncluster_membership\nMCBB.ClusterMembershipResult\nBase.sort!(cm::ClusterMembershipResult; ignore_first::Bool)\nBase.sum(cm::ClusterMembershipResult, indices::AbstractArray{Int,1})\nget_trajectory\ncluster_measure_mean\ncluster_measure_std\ncluster_measures\nMCBB.ClusterMeasureResult\ncluster_measures_sliding_histograms\nMCBB.ClusterMeasureHistogramResult\nClusterICSpaces\ncluster_n_noise\nmeasure_on_parameter_sliding_window\nk_dist(D::AbstractArray, k::Int=4)\nKNN_dist\nKNN_dist_relative","category":"page"},{"location":"ref/clustering_funcs/#MCBB.distance_matrix","page":"Clustering Functions","title":"MCBB.distance_matrix","text":" distance_matrix(sol::myMCSol, prob::myMCProblem, distance_func::Function, weights::AbstractArray; matrix_distance_func::Union{Function, Nothing}=nothing, histogram_distance_func::Union{Function, Nothing}=wasserstein_histogram_distance, relative_parameter::Bool=false, histograms::Bool=false, use_ecdf::Bool=true, k_bin::Number=1, bin_edges::AbstractArray)\n\nCalculate the distance matrix between all individual solutions.\n\nHistogram Method\n\nIf it is called with the histograms flag true, computes for each run in the solution sol for each measure a histogram of the measures of all system dimensions. The binning of the histograms is computed with Freedman-Draconis rule and the same across all runs for each measure.\n\nThe distance matrix is then computed given a suitable histogram distance function histogram_distance between these histograms.\n\nThis is intended to be used in order to avoid symmetric configurations in larger systems to be distinguished from each other. Example: Given a system with 10 identical oscillators. Given this distance calculation a state where oscillator 1-5 are synchronized and 6-10 are not syncronized would be in the same cluster as a state where oscillator 6-10 are synchronized and 1-5 are not synchronized. If you don't want this kind of behaviour, use the regular distance_matrix function.\n\nSparse and memory mapped options\n\nThere are seperate routines for computing very large matrices, using either memory maped arrays (see distance_matrix_mmap) or sparse arrays (see distance_matrix_sparse).\n\nArguments\n\nsol: solution\nprob: problem\ndistance_func: The actual calculating the distance between the measures/parameters of each solution with each other. Signature should be (measure_1::Union{Array,Number}, measure_2::Union{Array,Number}) -> distance::Number. Example and default is(x,y)->sum(abs.(x .- y))`.\nweights: Instead of the actual measure weights[i_measure]*measure is handed over to distance_func. Thus weights need to be N_meas+N_par long array.\n\nKwargs\n\nrelative_parameter: If true, the paramater values during distance calcuation is rescaled to [0,1]\nhistograms::Bool: If true, the distance calculation is based on distance_matrix_histogram with the default histogram distance wasserstein_histogram_distance.\nhistogram_distance_func: The distance function between two histograms. Default is wasserstein_histogram_distance.\nmatrix_distance_func: The distance function between two matrices or arrays or length different from N_dim. Used e.g. for Crosscorrelation.\necdf::Bool if true the histogram_distance function gets the empirical cdfs instead of the histogram\nk_bin::Int: Multiplier to increase (k_bin1) or decrease the bin width and thus decrease or increase the number of bins. It is a multiplier to the Freedman-Draconis rule. Default: k_bin=1\nnbin_default::Int: If the IQR is very small and thus the number of bins larger than nbin_default, the number of bins is set back to nbin_default and the edges and width adjusted accordingly.\nnbin::Int If specified, ingore all other histogram binning calculation and use nbin bins for the histograms.\nbin_edges::AbstractArray: If specified ignore all other histogram binning calculations and use this as the edges of the histogram (has to have one more element than bins, hence all edges). Needs to be an Array with as many elements as measures, if one wants automatic binning for one observables, this element of the array has to be nothing. E.g.: [1:1:10, nothing, 2:0.5:5].\n\nReturns an instance of DistanceMatrix or DistanceMatrixHist\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.distance_matrix_mmap","page":"Clustering Functions","title":"MCBB.distance_matrix_mmap","text":"distance_matrix_mmap(sol::myMCSol, prob::myMCProblem, distance_func::Function, weights::AbstractArray; matrix_distance_func::Union{Function, Nothing}=nothing, histogram_distance_func::Union{Function, Nothing}=wasserstein_histogram_distance, relative_parameter::Bool=false, histograms::Bool=false, use_ecdf::Bool=true, k_bin::Number=1, nbin_default::Int=50, el_type=Float32, save_name=\"mmap-distance-matrix.bin\")\n\nComputes the distance matrix like distance_matrix but uses memory-maped arrays. Use this if the distance matrix is too large for the memory of your computer. Same inputs as distance_matrix, but with added el_type that determines the eltype of the saved matrix and save_name the name of the file on the hard disk.\n\nDue to the restriction of memory-maped arrays saving and loading distance matrices computed like this with JLD2 will only work within a single machine. A way to reload these matrices / transfer them, is reload_mmap_distance_matrix.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.compute_distance","page":"Clustering Functions","title":"MCBB.compute_distance","text":"compute_distance(sol::myMCSol, i_meas::Int, distance_func::Function; use_histograms::Bool=false, use_ecdf::Bool=true, k_bin::Number=1, bin_edges::AbstractRange)\n\nComputes a (part of the) distance matrix for only a single measure i_meas. Follows otherwise the same logic as distance_matrix but returns the matrix as an Array{T,2}.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.distance_matrix_sparse","page":"Clustering Functions","title":"MCBB.distance_matrix_sparse","text":"distance_matrix_sparse(sol::myMCSol, prob::myMCProblem, distance_func::Function, weights::AbstractArray; matrix_distance_func::Union{Function, Nothing}=nothing, histogram_distance_func::Union{Function, Nothing}=wasserstein_histogram_distance, relative_parameter::Bool=false, histograms::Bool=false, use_ecdf::Bool=true, k_bin::Number=1, nbin_default::Int=50, nbin::Union{Int, Nothing}=nothing, bin_edges::Union{AbstractArray, Nothing}=nothing, sparse_threshold::Number=Inf, el_type=Float32, check_inf_nan::Bool=true)\n\nComputes the distance matrix sparse. Same arguments as distance_matrix with extra arguments\n\n* `sparse_threshold`: Only distances smaller than this value are saved\n* `check_inf_nan`: Only performs the Inf/NaN check if true.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.AbstractDistanceMatrix","page":"Clustering Functions","title":"MCBB.AbstractDistanceMatrix","text":"abstract type AbstractDistanceMatrix{T} <: AbstractArray{T,2} end\n\nAbstract Datatype for all Distance Matrix types. Currently, there are within MCBB:     * DistanceMatrix     * DistanceMatrixHist\n\n\n\n\n\n","category":"type"},{"location":"ref/clustering_funcs/#MCBB.DistanceMatrix","page":"Clustering Functions","title":"MCBB.DistanceMatrix","text":"DistanceMatrix{T}\n\nType for distance matrices. This type should behave just like any AbstractArray{T,2}. There's a convert to AbstractArray{T,2}.\n\nIt also holds additional information about the distance calculation.\n\nFields (and constructor)\n\ndata::AbstractArray{T,2}: The actual distance matrix\nweights::AbstractArray{T,1}: The weights that were used to compute it\ndistance_func::Function: The function that was used to compute it\nrelative_parameter::Bool: Was the parameter rescaled?\n\n\n\n\n\n","category":"type"},{"location":"ref/clustering_funcs/#MCBB.DistanceMatrixHist","page":"Clustering Functions","title":"MCBB.DistanceMatrixHist","text":"DistanceMatrixHist{T}\n\nType for distance matrices which were computed using Histograms. This type should behave just like any AbstractArray{T,2}. There's a convert to AbstractArray{T,2}.\n\nIt also holds additional information about the distance calculation.\n\nFields (and constructor)\n\ndata::AbstractArray{T,2}: The actual distance matrix\nweights::AbstractArray{T,1}: The weights that were used to compute it\ndistance_func::Function: The function that was used to compute the distance between the global measures\nmatrix_distance_func::Union{Function, Nothing}: The function that was used to compute it\nrelative_parameter::Bool: Was the parameter rescaled?\nhistogram_distance::Function: Function used to compute the histogram distance\nhist_edges: Array of arrays/ranges with all histogram edges\nbin_width: Array of all histogram bin widths\necdf: Was the ECDF used in the distance computation?\nk_bin: Additional factor in bin_width computation\n\n\n\n\n\n","category":"type"},{"location":"ref/clustering_funcs/#MCBB.metadata!-Tuple{AbstractDistanceMatrix}","page":"Clustering Functions","title":"MCBB.metadata!","text":"metadata!(dm::AbstractDistanceMatrix, )\n\nSets the input [AbstractDistanceMatrix] matrix itself empty, thus only containing metadata. This is usefull if the matrix itself is already saved otherwise (like with Mmap).\n\n\n\n\n\n","category":"method"},{"location":"ref/clustering_funcs/#MCBB.wasserstein_histogram_distance","page":"Clustering Functions","title":"MCBB.wasserstein_histogram_distance","text":"One possible histogram distance for distance_matrix_histogram (also the default one). It calculates the 1-Wasserstein / Earth Movers Distance between the two ECDFs by first computing the ECDF and then computing the discrete integral\n\nint_-infty^+inftyECDF(hist_1) - ECDF(hist_2) dx = sum_i  ECDF(hist_1)_i - ECDF(hist_2)_i  cdot bin_width.\n\nReturns a single (real) number. The input is the ecdf.\n\nAdopted from https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.ecdf_hist","page":"Clustering Functions","title":"MCBB.ecdf_hist","text":"ecdf_hist(hist::Histogram)\n\nReturns the ECDF of a histogram (normalized) as an Array.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.cluster_distance","page":"Clustering Functions","title":"MCBB.cluster_distance","text":"cluster_distance(sol::myMCSol, D::AbstractDistanceMatrix, cluster_results::ClusteringResult,  cluster_1::Int, cluster_2::Int; measures::Union{AbstractArray, Nothing}=nothing, distance_func=nothing, histogram_distance=nothing, matrix_distance_func=nothing, k_bin::Number=1)\n\nDoes calculate the distance between the members of two cluster seperatly for each measure\n\nInputs\n\nsol: Solution object\nD: distance matrix from distance_matrix\ncluster_results: results from the clustering\ncluster_1: Index of the first cluster to be analysed (noise/outlier cluster = 1)\ncluster_2: Index of the second cluster to be analysed\nmeasures: Which measures should be analysed, default: all.\n\nOutput\n\nArray with\nSummary dictionary, mean and std of the distances\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.cluster_means-Tuple{myMCSol,DbscanResult}","page":"Clustering Functions","title":"MCBB.cluster_means","text":"cluster_means(sol::myMCSol, clusters::ClusteringResult)\n\nReturns the mean of each measure for each cluster.\n\n\n\n\n\n","category":"method"},{"location":"ref/clustering_funcs/#MCBB.cluster_membership","page":"Clustering Functions","title":"MCBB.cluster_membership","text":"cluster_membership(par::AbstractArray, clusters::ClusteringResult)\n\nCalculates the proportion of members for each cluster for all parameter values.\n\nReturns an instance ClusterMembershipResult with fields:\n\npar: the center value of the sliding windows, in case multiple parameter are being varied, it is a meshgrid.\ndata: members of the clusters on the parameter grid\n\n\n\n\n\ncluster_membership(prob::myMCProblem, clusters::ClusteringResult, window_size::AbstractArray, window_offset::AbstractArray; normalize::Bool=true, min_members::Int=0)\ncluster_membership(prob::myMCProblem, clusters::ClusteringResult, window_size::Number, window_offset::Number; normalize::Bool=true,  min_members::Int=0)\n\nCalculates the proportion of members for each cluster within a parameter sliding window.\n\nprob: problem\nsol: solution of prob\nclusters: results from a DBSCAN run.\nwindow_size: Size of the window. In case multiple paramaters being varied has to be an array.\nwindow_offset: Offset of the sliding window. In case multiple paramaters being varied has to be an array.\n\nReturns an instance ClusterMembershipResult with fields:\n\npar: the center value of the sliding windows, in case multiple parameter are being varied, it is a meshgrid.\ndata: members of the clusters on the parameter grid\n\nThe results can be plotted with directly with plot(results, kwargs...). See ClusterMembershipResult for details on the plotting and operationg on this type.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.ClusterMembershipResult","page":"Clustering Functions","title":"MCBB.ClusterMembershipResult","text":"ClusterMembershipResult{T,S}\n\nStores the results of cluster_membership and can be used for ClusterMembershipPlot.\n\nFields\n\npar: Parameter Array or Mesh\ndata: Cluster Membership data on par-Parameter grid.\nmultidim_flag: Is the experiment multidimensional?\n\nPlot\n\nplot(cm::ClusterMembershipResult, kwargs...)\n\nDoes plot the ClusterMembershipResult. Uses Plot recipes and thus hands over all kwargs possible from Plots.jl.\n\nHints\n\nThe order of the labels for the legend is reversed.\n\nAdditional Kwargs\n\nplot_index: Range or Array with the indices of the clusters to be plotted. Default: all.\n\nAdditonal operation defined\n\n* can be indexed\n* can be sorted, [`Base.sort!(cm::ClusterMembershipResult; ignore_first::Bool)`](@ref)\n* can be summed, [`Base.sum(cm::ClusterMembershipResult, indices::AbstractArray{Int,1})`](@ref)\n\n\n\n\n\n","category":"type"},{"location":"ref/clustering_funcs/#Base.sort!-Tuple{ClusterMembershipResult}","page":"Clustering Functions","title":"Base.sort!","text":"sort!(cm::ClusterMembershipResult; ignore_first::Bool=false)\n\nSorts cm inplace by the count of members of the clusters from low to high. If ignore_first is true, the first cluster (with DBSCAN this is the outlier cluster) is ignored while sorting and remains the first cluster.\n\n\n\n\n\n","category":"method"},{"location":"ref/clustering_funcs/#Base.sum-Tuple{ClusterMembershipResult,AbstractArray{Int64,1}}","page":"Clustering Functions","title":"Base.sum","text":"Base.sum(cm::ClusterMembershipResult, indices::AbstractArray{Int,1})\n\nReturns a ClusterMembershipResult with all indices clusters summed together.\n\n\n\n\n\n","category":"method"},{"location":"ref/clustering_funcs/#MCBB.get_trajectory","page":"Clustering Functions","title":"MCBB.get_trajectory","text":"get_trajectory(prob::MCBBProblem, sol::MCBBSol, clusters::ClusteringResult, i::Int; only_sol::Bool=true)\n\nSolves and returns a trajectory that is classified in cluster i. Randomly selects one IC/Parameter configuration, so that mulitple executions of this routine will yield different results! If only_sol==true it returns only the solution, otherwise it returns a tuple (solution, problem, i_run) where i_run is the number of the trial in prob and sol.\n\nget_trajectory(prob::MCBBProblem, sol::MCBBSol, i::Int, only_sol::Bool=true)\n\nSolves problem i and returns a trajectory. If only_sol==true it returns only the solution, otherwise it returns a tuple (solution, problem, i_run) where i_run is the number of the trial in prob and sol.\n\nExample\n\nPlot with e.g\n\nusing PyPlot\nIM = imshow(Matrix(get_trajectory(prob,sol,db_res,1)), aspect=2)\nylabel(\"System Dimension i\")\nxlabel(\"Time t\")\ncb = colorbar(IM, orientation=\"horizontal\")\ncb[:ax][:set_xlabel](\"Colorbar: Im(z)\", rotation=0)\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.cluster_measure_mean","page":"Clustering Functions","title":"MCBB.cluster_measure_mean","text":"cluster_measure_mean(sol::myMCSol, clusters:ClusteringResult, i::Int)\n\nReturn the Mean of measure i for each cluster.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.cluster_measure_std","page":"Clustering Functions","title":"MCBB.cluster_measure_std","text":"cluster_measure_std(sol::myMCSol, clusters:ClusteringResult, i::Int)\n\nReturn the std of measure i for each cluster.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.cluster_measures","page":"Clustering Functions","title":"MCBB.cluster_measures","text":" cluster_measures(prob::myMCProblem, sol::myMCSol, clusters::ClusteringResult, window_size::AbstractArray, window_offset::AbstractArray)\n cluster_measures(prob::myMCProblem, sol::myMCSol, clusters::ClusteringResult, window_size::Number, window_offset::Number)\n\nCalculated the measures for each cluster along a sliding window. Can also handle multiple parameters being varied.\n\nprob: problem\nsol: solution of prob\nclusters: results from a DBSCAN run.\nwindow_size: Size of the window. In case multiple paramaters being varied has to be an array.\nwindow_offset: Offset of the sliding window. In case multiple paramaters being varied has to be an array.\n\nReturns an instance of ClusterMeasureResult with fields:\n\npar: the center value of the sliding windows, in case multiple parameter are being varied, it is a meshgrid.\ncluster_measures: (per dimension) measures on the parameter grid\ncluster_measures_global: global measures on the parameter grid\n\nPlot:\n\nThe i-th measure can be plotted with plot(res::ClusterMeasureResult, i::Int, kwargs...)\nA single cluster and measure can be plotted with plot(res::ClusterMeasureResult, i_meas::Int, i_cluster::Int, kwargs...).\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.ClusterMeasureResult","page":"Clustering Functions","title":"MCBB.ClusterMeasureResult","text":"ClusterMeasureResult\n\nResults of cluster_measures.\n\nFields:\n\npar\ncluster_measures\ncluster_measures_global\n\nPlot:\n\nThe i-th measure of the j-th cluster can be plotted with plot(res::ClusterMeasureResult, i::Int, j::Int, kwargs...)\n\n\n\n\n\n","category":"type"},{"location":"ref/clustering_funcs/#MCBB.cluster_measures_sliding_histograms","page":"Clustering Functions","title":"MCBB.cluster_measures_sliding_histograms","text":"cluster_measures_sliding_histograms(prob::myMCProblem, sol::myMCSol, clusters::ClusteringResult, i_meas::Int, window_size::Number, window_offset::Number; kwargs...)\n\nCalculates for each window in the sliding window array a histogram of all results of meausure i_meas of all runs seperatly for each cluster.\n\nInput:\n\nprob::myMCProblem: problem\nsol::myMCSol: solution object\nclusters::ClusteringResult: cluster results\ni_meas::Int: index of the measure to be analyzed\nwindow_size::AbstractArray: size of the window, number or Array with length according to the number of parameters\nwindow_offset::AbstractArray: size of the window, number or Array with length according to the number of parameters\n\nKeyword arguments\n\nk_bin::Number: Bin Count Modifier. k_bin-times the Freedman Draconis rule is used for binning the data. Default: 1\nnormalization_mode::Symbol, normalization mode applied to Histograms. Directly handed over to normalize.\nnbin::Int: Uses nbins for the histograms instead of the (automatic) Freedman Draconis rule\nbin_edges::AbstractRange: Uses these edges for the histograms.\nstate_filter::AbstractArray: Only use these system dimension as the basis for the computation, default: all. Attention: if the evalation function already used a state_filter this will be refering only to the system dimension that were measured.\n\nReturns an instance of ClusterMeasureHistogramResult with fields:\n\nhist_vals: Ncluster, Nwindows..., N_bins - sized array with the value of the histograms for each window\npar: midpoint of the sliding windows, \"x-axis-labels\" of the plot\nhist_bins: center of the bins, \"y-axis-label\" of the plot\n\nCan be plotted with plot(res::ClusterMeasureHistogramResult, kwargs...). See ClusterMeasureHistogramResult for details.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.ClusterMeasureHistogramResult","page":"Clustering Functions","title":"MCBB.ClusterMeasureHistogramResult","text":"ClusterMeasureHistogramResult\n\nStores results of cluster_measures_sliding_histograms.\n\nFields\n\nhist_vals: Ncluster, Nwindows..., N_bins - sized array with the value of the histograms for each window\npar: midpoint of the sliding windows, \"x-axis-labels\" of the plot\nhist_edges: center of the bins, \"y-axis-label\" of the plot\nmultidim_flag\n\nPlot\n\nCan be plotted with plot(res::ClusterMeasureHistogramResult, i, kwargs...). With i being the number of the cluster.\n\n\n\n\n\n","category":"type"},{"location":"ref/clustering_funcs/#MCBB.ClusterICSpaces","page":"Clustering Functions","title":"MCBB.ClusterICSpaces","text":"ClusterICSpaces\n\nThis function/struct returns the distributions as histograms of ICs (and Parameter) in each dimension for cluster seperatly, it also returns the data itself, means and stds. If additional keyword arguments minpar, maxpar are given, it limits the analysis to the specified parameter range.\n\nFields of the struct:\n\ndata: array of array of arrays, the ICs and pars for each cluster and dimension\nhistograms: Ncluster x Ndim Array of Histograms of ICs/Par\nmeans: Means of each dimension for each cluster\nstds: Stds of each dimension for each cluster\ncross_dim_means: list of Means of ICs across IC-dimensions per Cluster\ncross_dim_stds: list of Std of ICs across IC-dimensions per Cluster\ncross_dim_kurts: list of Kurtosis of ICs across IC-dimensions per Cluster\n\nConstructor\n\nClusterICSpaces(prob::myMCProblem, sol::myMCSol, clusters::ClusteringResult; min_par::Number=-Inf, max_par::Number=Inf, nbins::Int64=20)\n\nprob: Problem\nsol: solution of prob\nclusters: DBSCAN results\nmin_par, max_par: restrict the analysis to parameters within this value range\nnbins: Number of bins of the histograms\n\n\n\n\n\n","category":"type"},{"location":"ref/clustering_funcs/#MCBB.cluster_n_noise","page":"Clustering Functions","title":"MCBB.cluster_n_noise","text":"cluster_n_noise(clusters::ClusteringResult)\n\nReturns the number of points assignt to the \"noise\" cluster (somehow this is not automaticlly returned by the routine of Clustering.jl).\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.measure_on_parameter_sliding_window","page":"Clustering Functions","title":"MCBB.measure_on_parameter_sliding_window","text":"measure_on_parameter_sliding_window\n\nDoes calculate measures (per cluster) on parameter sliding windows. This routine is called by cluster_membership and cluster_measures but can also be used for plotting measures on the parameter grid manually.\n\nATTENTION: If a cluster has no members within a window the value is set to NaN. This should simply omit these points from beeing plotted (while missing and nothing are currently not compatible with most plotting packages).\n\nmeasure_on_parameter_sliding_window(prob::myMCProblem, sol::myMCSol, i::Int, clusters::ClusteringResult, window_size::Number, window_offset::Number)\n\nDoes return the i-th measure for each cluster seperatly on the parameter sliding window grid\n\nprob: Problem\nsol: solution of prob\ni: function returns the i-th measure\nclusters: results from a DBSCAN run.\nwindow_size: Size of the window. In case multiple paramaters being varied has to be an array.\nwindow_offset: Offset of the sliding window. In case multiple paramaters being varied has to be an array.\nmeasureonparameterslidingwindow(prob::myMCProblem, sol::myMCSol, i::Int, windowsize::Number, windowoffset::Number)\n\nDoes return the i-th measure on the parameter sliding window grid (does not calculate the measure for each cluster seperatly)\n\nAll methods return a tuple with:\n\nparameter_windows: the center value of the sliding windows, in case multiple parameter are being varied, it is a meshgrid.\ncluster_measures: members of the clusters on the parameter grid\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.k_dist","page":"Clustering Functions","title":"MCBB.k_dist","text":" k_dist(D::AbstractArray, k::Int=4)\n\nHelper function for estimating a espilon value for DBSCAN. In the original paper, Ester et al. suggest to plot the k-dist graph (espacially for k=4) to estimate a value for eps given minPts = k. It computes the distance to the k-th nearast neighbour for all data points given their distance matrix.\n\nD: Distance matrix\nk: calculate the distance to the k-th neighbour\n\nReturns sorted array with the k-dist of all elements of D.\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.KNN_dist","page":"Clustering Functions","title":"MCBB.KNN_dist","text":"KNN_dist(D::AbstractArray, K::Int)\n\nReturns the cumulative K-th nearest neighbour distance.\n\nD: Distance matrix\nK\n\n\n\n\n\n","category":"function"},{"location":"ref/clustering_funcs/#MCBB.KNN_dist_relative","page":"Clustering Functions","title":"MCBB.KNN_dist_relative","text":"KNN_dist_relative(D::AbstractArray, rel_K::Float64=0.005)\n\nReturns the cumulative distance to the rel_K*N nearest neighbour.\n\nD: Distance matrix\nrel_K\n\n\n\n\n\n","category":"function"},{"location":"ref/evaluation_funcs/#Evaluation-Functions-1","page":"Evaluation Functions","title":"Evaluation Functions","text":"","category":"section"},{"location":"ref/evaluation_funcs/#","page":"Evaluation Functions","title":"Evaluation Functions","text":"eval_ode_run\nempirical_1D_KL_divergence_hist\nempirical_1D_KL_divergence_pc\nwasserstein_ecdf\ncorrelation\ncorrelation_hist\ncorrelation_ecdf\ncheck_inf_nan","category":"page"},{"location":"ref/evaluation_funcs/#MCBB.eval_ode_run","page":"Evaluation Functions","title":"MCBB.eval_ode_run","text":"eval_ode_run\n\nEvaluation functions for the EnsembleProblem. Given a set of measures the solution sol is evaluated seperatly per dimension. An additional set of global measures take in the complete solution and return a single number or a matrix. Handing over this function to DEMCBBProblem (and thus also to EnsembleProblem) the expected signature is (sol, i::Int) -> (results, repeat::Bool). Here, there are several more general versions that can be adjusted to the experiment.\n\neval_ode_run(sol, i, state_filter::Array{Int64,1}, eval_funcs::Array{<:Function,1}, matrix_eval_funcs::Union{AbstractArray, Nothing}=nothing, global_eval_funcs::Union{AbstractArray, Nothing}=nothing; failure_handling::Symbol=:None, cyclic_setback::Bool=false, replace_inf=nothing, flag_past_measures=false, state_filter_only_per_dim=false)\n\nsol: solution of one of the EnsembleProblem runs, should have only timesteps with constant time intervals between them\ni: Int, number of iteration/run\nstate_filter: Array with indicies of all dimensions (of the solutions) that should be evaluated\neval_funcs: Array of functions that should be applied to every dimension of the solution. Signature: (sol::AbstractArray) -> measure or (sol::AbstractArray, previous_results::AbstractArray) -> measure depending on the value of flag_past_measures.\nmatrix_eval_funcs: Array of functions that should be applied to the complete Ndimensional solution and return a matrix (or vector), like e.g covariance or correlation, signature (N-Dim Array w/ Samples ::AbstractArray) -> Measure::AbstractArray (technical detail: length(measure)!=Ndim (system dimension))\nglobal_eval_funcs: Array of functions that should be applied to the complete N-dimensional solution, signature (N-Dim Array w/ Samples ::AbstractArray) -> Measure::Number\nfailure_handling: How failure of integration is handled. Should be :None (do no checks), :Inf (If retcode==:DtLessThanMin: return Inf) or :Repeat (If no succes, repeat the trial (only works with random initial conditions))\ncyclic_setback: Bool, if true N*2pi is substracted from the solution so that the first element of the solution that is analysed is within -pi pi. Usefull e.g. for phase oscillators.\nreplace_inf: Number or Nothing, if a number replaces all Infs in the solution with this number. Can be usefull if one still wants to distinguish between different solutions containing Infs, +Inf is replaced by the Number, -Inf by (-1)*Number.\nflag_past_measures::Bool: If true als function within eval_funcs also receive the previous results (of the other measures for the same dimension) as an extra arguments. Thus all functions need to have a signature (sol::AbstractArray, previous_results::AbstractArray) -> measure. If false the functions only receive the solution vector, thus the function should have the signature (sol::AbstractArray) -> measure\nstate_filter_only_per_dim: Only per-dimension measures are affected by the state_filter.\n\nExample function\n\nIn order to derive a valid evaluation function from this for the MCBBProblem one can define a function similar to this:\n\nfunction my_eval_ode_run(sol, i)\n    N_dim = length(sol.prob.u0)\n    state_filter = collect(1:N_dim)\n    eval_funcs = [mean, std]\n    eval_ode_run(sol, i, state_filter, eval_funcs)\nend\n\nUtilizing previous results\n\nIf one wants to utilze the previous results (and don't compute measures twice), one has to use the flag_past_measures=true option. This is only possible for the per dimension measures. An example could read:\n\nfunction my_eval_ode_run(sol, i)\n    N_dim = length(sol.prob.u0)\n    state_filter = collect(1:N_dim)\n    meanval(u::AbstractArray, past_measures::AbstractArray) = StatsBase.mean(u)\n    standarddev(u::AbstractArray, past_measures::AbstractArray) = StatsBase.std(u; mean=past_measures[1], corrected=false)\n    eval_funcs = [meanval, standarddev, empirical_1D_KL_divergence_hist]\n    eval_ode_run(sol, i, state_filter, eval_funcs; flag_past_measures=true)\nend\n\nLatter function is also already available as a default eval_ode_run in this library. The order of the functions is important. In this example meanval will always get an empty array as the second argument, standarddev will get an array with the result from meanval as the only value and empirical_1D_KL_divergence_hist will get an additional array with the results from meanval and standarddev.\n\neval_ode_run(sol, i)\n\nDefault eval_ode_run, identical to the code above.\n\nContinue Integration / Response Analysis\n\n eval_ode_run(sol, i, state_filter::Array{Int64,1}, eval_funcs::Array{<:Function,1},  matrix_eval_funcs::Union{AbstractArray, Nothing}, global_eval_funcs::Union{AbstractArray, Nothing}, par_var::OneDimParameterVar, eps::Float64, par_bounds::AbstractArray, distance_matrix_func; failure_handling::Symbol=:None, cyclic_setback::Bool=false, flag_past_measures::Bool=false, N_t::Int=200, alg=nothing, debug::Bool=false, return_pm::Bool, new_tspan::Union{Nothing, AbstractArray}, kwargs...)\n\nEvaluation function that continues each integration and computes the same measures for par+eps and par-eps. Returns the results of the usual eval_ode_run (all measures) and additionally the response of the distance function to the paramater increase/decrease.\n\npar_var: ParameterVar struct, same as handed over to the problem type.\neps: Number, response at par+/-eps\ndistance_matrix_func: Same distance matrix functions that will also be used for the later analysis/clustering, expected signature: (sol::MCBBSol, prob::MCBBProblem) -> D::AbstractArray, . Attension: if the weight vector is provided this version of the distance it needs to have one less element as the function later used before clustering because the result of the response analysis is an additional measure.\nN_t: Time steps for the continued integration\nalg: Algorithm for solve()\ndebug: If true, also returns the DifferentialEquations problem solved for the continuation.\nreturn_pm: If true, returns D(p+dp) AND D(p-dp). If false returns the mean of these.\nnew_tspan: timespan for continued integeration, default: 15% of the original timespan\nall further keyword arguments will be handed over to solve(prob::DEMCBBProblem, ...)\n\n\n\n\n\n","category":"function"},{"location":"ref/evaluation_funcs/#MCBB.empirical_1D_KL_divergence_hist","page":"Evaluation Functions","title":"MCBB.empirical_1D_KL_divergence_hist","text":"empirical_1D_KL_divergence_hist(u::AbstractArray, mu::Number, sig::Number, hist_bins::Int=31, n_stds::Number=3, sig_tol=1e-4::Number)\n\nOne measure that can be used with eval_ode_run. Computes the empirical Kullback-Leibler Divergence of the input to a normal distribution with the same mean and std as the input, thus it is a measure of normality. This version does this with histograms.\n\nu: Input Array\nmu: Mean of u\nsig: Std of u\nhist_bins: number of bins of the histogram to estimate the empirical pdf of the data\nn_stds: Interval that the histogram covers in numbers of stds (it covers  mean +/- n_stds*std)\nsig_tol: At times, all KL div methods run into difficulties when sig gets really small, for sig<sig_tol 0 is returned as a result because in the limit of sig -> 0 the reference distribution is a delta distribution and the data is constant thus also a delta distribution. hence the distributions are identical and the KL div should be zero.\n\n\n\n\n\n","category":"function"},{"location":"ref/evaluation_funcs/#MCBB.empirical_1D_KL_divergence_pc","page":"Evaluation Functions","title":"MCBB.empirical_1D_KL_divergence_pc","text":"empirical_1D_KL_divergence_pc(u::AbstractArray, mu::Number, sig::Number)\n\nOne measure that can be used with eval_ode_run. Computes the empirical Kullback-Leibler Divergence of the input to a normal distribution with the same mean and std as the input, thus it is a measure of normality. This version does this based on a linearly interpolated emperical CDF, see Perez-Cruz (IEEE, 2008). This version can run into numerical difficulties for discrete systems with alternating inputs like [a,-a,a,a] and large 2a. For reasonable continous input it is a better and parameter free approximation to the KL divergence than the histogram estimator.\n\nu: Input Array\nmu: Mean of u\nsig: Std of u\n\n\n\n\n\n","category":"function"},{"location":"ref/evaluation_funcs/#MCBB.wasserstein_ecdf","page":"Evaluation Functions","title":"MCBB.wasserstein_ecdf","text":"wasserstein_ecdf(u::AbstractArray, mu::Number, sig::Number)\n\nOne measure that can be used with eval_ode_run. Computes the 1-wasserstein distance based on ECDFs.\n\nu: Input Array\nmu: Mean of u\nsig: Std of u\n\n\n\n\n\n","category":"function"},{"location":"ref/evaluation_funcs/#MCBB.correlation","page":"Evaluation Functions","title":"MCBB.correlation","text":"correlation(sol::AbstractArray)\n\nExample function for matrix_eval_funcs. This routine calculates the absolute value of the Pearson correlation between the time series of all system dimensions and returns it as a matrix.\n\n\n\n\n\n","category":"function"},{"location":"ref/evaluation_funcs/#MCBB.correlation_hist","page":"Evaluation Functions","title":"MCBB.correlation_hist","text":"correlation_hist(sol::AbstractArray, nbins::Int=30)\n\nExample function for matrix_eval_funcs. This routine calculates the absolute value of the Pearson correlation between the time series of all system dimensions and returns the weights of histogram fitted to all of these values. It uses the same binning for all calculations with the edges calculated by 0:1. /nbins:1.\n\n\n\n\n\n","category":"function"},{"location":"ref/evaluation_funcs/#MCBB.correlation_ecdf","page":"Evaluation Functions","title":"MCBB.correlation_ecdf","text":"correlation_ecdf(sol::AbstractArray, nbins::Int=30)\n\nExample function for matrix_eval_funcs. This routine calculates the absolute value of the Pearson correlation between the time series of all system dimensions and the ECDF of a histogram fitted to all of these values. It uses the same binning for all calculations with the edges calculated by 0:1. /nbins:1.\n\n\n\n\n\n","category":"function"},{"location":"ref/evaluation_funcs/#MCBB.check_inf_nan","page":"Evaluation Functions","title":"MCBB.check_inf_nan","text":"check_inf_nan(sol::myMCSol)\n\nChecks if any of the results is inf or nan and returns the indices in a dictionary with keys Inf and NaN\n\n\n\n\n\n","category":"function"},{"location":"custom_problems/#Custom-Problem-1","page":"Custom Problem","title":"Custom Problem","text":"","category":"section"},{"location":"custom_problems/#","page":"Custom Problem","title":"Custom Problem","text":"The library also allows for the analysis of problems that can not be solved with DifferentialEquations as an backend such as Multi-Agent Simulations or models that need to run other external code. These kind of problems can be analyzed with the help of CustomMCBBProblem. It is programmed to mirror the behaviour of DifferentialEquations. A longer how-to will follow, but for now a look in the references can help you for the start.  ","category":"page"},{"location":"ref/problem_types/#Problem-Types-1","page":"Problem Types","title":"Problem Types","text":"","category":"section"},{"location":"ref/problem_types/#","page":"Problem Types","title":"Problem Types","text":"myMCProblem\nMCBBProblem\nDEMCBBProblem\nparameter(p::MCBBProblem, i::Int; complex_returns_abs=true)\nMCBBSol\nDEMCBBSol\nsort(sol::MCBBSol, prob::MCBBProblem, i::Int=1)\nsort!(sol::MCBBSol, prob::MCBBProblem, i::Int=1)\nsort(prob::MCBBProblem, i::Int=1)\nsort!(prob::MCBBProblem, i::Int=1)\nshow_results\nget_measure\nnormalize(sol::DEMCBBSol, k::AbstractArray)\nsolve(prob::DEMCBBProblem, alg=nothing, N_t=400::Int, parallel_type=:parfor; flag_check_inf_nan=true, custom_solve::Union{Function,Nothing}=nothing, kwargs...)\nsave\nload_prob\nload_sol","category":"page"},{"location":"ref/problem_types/#MCBB.myMCProblem","page":"Problem Types","title":"MCBB.myMCProblem","text":"myMCProblem\n\nAbstract type for all problem types defined in this library. Note that the DifferentialEquations.jl problem types are not  supertypes of this types.\n\n\n\n\n\n","category":"type"},{"location":"ref/problem_types/#MCBB.MCBBProblem","page":"Problem Types","title":"MCBB.MCBBProblem","text":"MCBBProblem <: myMCProblem\n\nAbstract type of DEMCBBProblem (using DifferentialEquations.jl as a backend) and CustomMCBBProblem (using customized solve and problem functions).\n\n\n\n\n\n","category":"type"},{"location":"ref/problem_types/#MCBB.DEMCBBProblem","page":"Problem Types","title":"MCBB.DEMCBBProblem","text":"DEMCBBProblem\n\nDifferential Equations Monte Carlo Basin Bifurcation Problem: Main type for the sample based bifurcation/stablity analysis based on EnsembleProblem from DifferentialEquations. This struct holds information about the underlying differential equation and the parameters and initial conditions its supposed to be solved for. Many points from the initial conditions - parameter space are sampled. When solved the solutions is evaluated seperatly for each dimension and certain statistical measures like mean or standard deviation are saved.\n\nThe struct has several different constructors following below.\n\nNote that its supertypes are MCBBProblem and myMCProblem, but not any of the DifferentialEquations abstract problem types.\n\nThe struct has the following fields:\n\np: EnsembleProblem to be solved, part of DifferentialEquations\nN_mc: Number of (Monte Carlo) runs to be solved\nrel_transient_time: Only after this time (relative to the total integration time) the solutions are evaluated\nic: (N_mc times (N_dim_ic + N_par))-Matrix containing initial conditions for each run.\npar: (``N{mc} \\times N{par})-Matrix containitng parameter values for each run\npar_var: ParameterVar, information about how the parameters are varied, see ParameterVar\n\nConstructors\n\nThe type has three different main constructors and several others that do automatic type conversions of appropiate tuples to ParamterVar types or of functions and arrays to arrays of functions/arrays if needed.\n\nRandomized Initial conditions\n\nDEMCBBProblem(p::DiffEqBase.DEProblem, ic_gens::Array{<:Function,1}, N_ic::Int, pars::DEParameters, par_range_tuple::ParameterVar, eval_ode_func::Function, tail_frac::Number)\n\nSetup a DEMCBBProblem with randomized initial conditions (and parameters).\n\np: A Problem from DifferentialEquations, currently supported are DiscreteProblem, ODEProblem, SDEProblem,DDEProblem the base problem one is interested in.\nic_gens: A function or an array of functions that generate the initial conditions for each trial. Function signature is ()->new_value::Number or (i_run)->new_value::Number or ()->new_value::AbstractArray or (i_run)->new_value::AbstractArray. If only one function is provided its used for all IC dims, if MN_dim functions with N_dim=kcdot M are provided these functions are repeated k times (usefull e.g. for coupled chaotic oscillators).\nN_ic: Number of trials to be computed, if parameter variation is varied by an array/range, N_ic is the number of initial conditions for each parameter value. Each parameter step then has the same N_ic idential initial conditions.\npars: parameter struct of the underlying system\npar_range_tuple:  ParameterVar, information about how the parameters are varied, see ParameterVar. Its also possible to hand over an appropiate tuple that will be automaticly converted to a ParameterVar type. A tuple of (First: name of the parameter as a symbol, Second: AbstractArray or Function that contains all parameters for the experiment or a function that generates parameter values. The function has to be format (oldvalue) -> (newvalue), Third: OPTIONAL: a function that maps (oldparameterinstance; (parrange[1],newparametervalue)) -> newparameterinstance. Default is 'reconstruct' from @withkw/Parameters.jl is used) For examples see Basic Usage.\neval_ode_func: Evaluation function for the EnsembleProblem with the signature (sol,i)->(results, repeat). There are many premade functions for this purpose in this library, most of them called eval_ode_run, see also eval_ode_run\ntail_frac: Only after this time (relative to the total integration time) the solutions are evaluated\n\nNon-randomized initial conditions\n\nDEMCBBProblem(p::DiffEqBase.DEProblem, ic_ranges::Array{<:AbstractArray,1}, pars::DEParameters, par_range_tuple::ParameterVar, eval_ode_func::Function, tail_frac::Number)\n\nSetup a DEMCBBProblem with initial conditions (and parameters) from predefined arrays or ranges. All arguments are identical to the other constructor except for:\n\nic_ranges: A range/array or array of ranges/arrays with initial conditions for each trial. If only one range/array is provided its used for all IC dims.\nNote that there is no N_ic argument in constrast to the other constructor\n\nHidden / Background Parameter Problem with Identical ICs\n\nIn case we are varying hidden/background parameters at each trial and keep the ICs constant, we can use the regular call\n\nDEMCBBProblem(p::DiffEqBase.DEProblem, ics::Array{Number,1}, pars::DEParameters, par_range_tuple::HiddenParameterVar, eval_ode_func::Function, tail_frac::Number)\n\nbut replace the ic_ranges argument, with an array ics that contains the constant ICs and the parameter variation has to be given as a HiddenParameterVar.\n\nDirect constructor\n\nIt is also possible to initialize the type directly with its fields with\n\nDEMCBBProblem(p::EnsembleProblem, N_mc::Int64, rel_transient_time::Float64, ic::AbstractArray, par::AbstractArray, par_range_tuple::ParameterVar)\n\n\n\n\n\n","category":"type"},{"location":"ref/problem_types/#MCBB.parameter-Tuple{MCBBProblem,Int64}","page":"Problem Types","title":"MCBB.parameter","text":"parameter(p::DEMCBBProblem, i::Int=1; complex_returns_abs=true)\n\nUtility function that returns the parameters of each trial of of a problem. In case multiple parameters are varied simultaneously it returns the i-th parameter. In case the initial conditions or parameters are complex valued the function returns the absolute value of the parameters if complex_returns_abs==true and the original complex number if complex_returns_abs==false.\n\n\n\n\n\n","category":"method"},{"location":"ref/problem_types/#MCBB.MCBBSol","page":"Problem Types","title":"MCBB.MCBBSol","text":"MCBBSol <: myMCSol\n\nAbstract type of DEMCBBSol (using DifferentialEquations.jl as a backend) and CustomMCBBSolution (using customized solve and problem functions).\n\n\n\n\n\n","category":"type"},{"location":"ref/problem_types/#MCBB.DEMCBBSol","page":"Problem Types","title":"MCBB.DEMCBBSol","text":"DEMCBBSol\n\nType that stores the solutions of a DEMCBBProblem. Is returned by the corresponding solve routine.\n\nIts fields are:\n\nsol: EnsembleSolution (see DifferentialEquations)\nN_mc: number of solutions saved / Monte Carlo trials runs\nN_t: number of time steps for each solutions\nN_dim: dimension measured with per dimension measures. if no state_filter was applied this is equal to the sytem dimension\nN_meas: number of measures used, ``N{meas} = N{meas{dim}} + N{meas_{global}}\nN_meas_dim: number of measures that are evalauted for every dimension seperatly\nN_meas_global: number of measures that are evalauted globally\nsolve_command: A function that solves one individual run/trial with the same settings as where used to\n\nNote, in case N_dim==1 => N_meas_global == 0 and N_meas_dim == N_meas\n\n\n\n\n\n","category":"type"},{"location":"ref/problem_types/#Base.sort","page":"Problem Types","title":"Base.sort","text":"sort(sol::DEMCBBSol, prob::DEMCBBProblem, i::Int=1)\n\nReturns a copy of the sol and prob sorted by the values of the i-th parameter.\n\n(In case the parameter is complex valued, it sorts by the absolute value of the parameter)\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#Base.sort!","page":"Problem Types","title":"Base.sort!","text":"sort(sol::DEMCBBSol, prob::DEMCBBProblem, i::Int=1)\n\nSorts sol and prob inplace by the values of the i-th parameter.\n\n(In case the parameter is complex valued, it sorts by the absolute value of the parameter)\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#Base.sort","page":"Problem Types","title":"Base.sort","text":"sort(prob::DEMCBBProblem, i::Int=1)\n\nReturns a copy of prob sorted by the values of the i-th paramater.\n\n(In case the parameter is complex valued, it sorts by the absolute value of the parameter)\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#Base.sort!","page":"Problem Types","title":"Base.sort!","text":"sort(prob::DEMCBBProblem, i::Int=1)\n\nSorts prob inplace by the values of thei-th paramater.\n\n(In case the parameter is complex valued, it sorts by the absolute value of the parameter)\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#MCBB.show_results","page":"Problem Types","title":"MCBB.show_results","text":"show_results(sol::DEMCBBSol, prob::DEMCBBProblem, min_par::Number, max_par::Number, i::Int=1, sorted::Bool=false)\n\nReturns the solutions for which the i-th parameter exhibits values between min_par and max_par. If sorted==true it assumes that sol and prob are already sorted by this parameter.\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#MCBB.get_measure","page":"Problem Types","title":"MCBB.get_measure","text":"get_measure(sol::MCBBSol, k::Int; state_filter::Union{AbstractArray, Nothing}=nothing)\n\nReturn the results for the k-th measure as an array. State_filter filters the system dimensions, e.g. if state_filter==1:10 only the first measurements from the first 10 system dimensions are returned. Default: all. This works only for the per dimenension measures of course. Attention: if the evalation function already used a state_filter this will be refering only to the system dimension that were measured.\n\n\n\n\n\nget_measure(sol::myMCSol, i::Int, clusters::ClusteringResult, i_cluster::Int, prob::Union{MCBBProblem,Nothing}=nothing, min_par::Number=-Inf, max_par::Number=+Inf, i_par::Int=1)\n\nGet measure i for the i_cluster-th cluster with parameter values between min_par and max_par. If no prob is given, it ignores the parameter values. In case a multidimensional setup is used, uses the i_par-th Parameter.\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#LinearAlgebra.normalize-Tuple{DEMCBBSol,AbstractArray}","page":"Problem Types","title":"LinearAlgebra.normalize","text":"normalize(sol::DEMCBBSol, k::AbstractArray)\n\nReturns a copy of sol with the solutions normalized to be in range [0,1]. It is possible to only select that some of the measures are normalized by providing an array with the indices of the measures that should be normalized, e.g. [1,2] for measure 1 and measure 2 to be normalized.\n\nnormalize(sol::DEMCBBSol)\n\nIf no extra array is provided, all measures are normalized.\n\n\n\n\n\n","category":"method"},{"location":"ref/problem_types/#DiffEqBase.solve","page":"Problem Types","title":"DiffEqBase.solve","text":"solve(prob::DEMCBBProblem, alg=nothing, N_t=400::Int, parallel_type=:parfor; flag_check_inf_nan=true, custom_solve::Union{Function,Nothing}=nothing, kwargs...)\n\nCustom solve for the DEMCBBProblem. Solves the EnsembleProblem, but saves and evaluates only after transient at a constant step size, the results are sorted by parameter value.\n\nprob: EnsembleProblem of type defined in this library\nalg: Algorithm to use, same as for solve() from DifferentialEquations.jl\nN_t: Number of timesteps to be saved\nparallel_type: Which form of parallelism should be used? Same as for EnsembleProblem from DifferentialEquations.jl\nflag_check_inf_nan: Does a check if any of the results are NaN or inf\ncustom_solve:: Function/Nothing, custom solve function\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#(Semi)-Internal-functions-1","page":"Problem Types","title":"(Semi) Internal functions","text":"","category":"section"},{"location":"ref/problem_types/#","page":"Problem Types","title":"Problem Types","text":"The following functions are usually not needed by the user as they are called automatically. They are still exported as they can be useful for some custom cases.","category":"page"},{"location":"ref/problem_types/#","page":"Problem Types","title":"Problem Types","text":"setup_ic_par_mc_problem\ndefine_new_problem\ntsave_array","category":"page"},{"location":"ref/problem_types/#MCBB.setup_ic_par_mc_problem","page":"Problem Types","title":"MCBB.setup_ic_par_mc_problem","text":"setup_ic_par_mc_problem\n\nMethods that are usually called automaticly while constructing a DEMCBBProblem. These methods setup the initial conditions - parameter matrix and the problem function for the EnsembleProblem.\n\nInitial Condtions set with Arrays or Ranges\n\nsetup_ic_par_mc_problem(prob::DiffEqBase.DEProblem, ic_ranges::Array{T,1}, parameters::DEParameters, var_par::ParameterVar) where T <: AbstractArray\n\nprob: A Problem from DifferentialEquations, currently supported are DiscreteProblem, ODEProblem, SDEProblem, the base problem one is interested in.\nic_ranges: A range/array or array of ranges/arrays with initial conditions for each trial. If only one range/array is provided its used for all IC dims.\nparameters: parameter struct of the underlying system\nvar_par:  ParameterVar, information about how the parameters are varied, see ParameterVar. Its also possible to hand over an appropiate tuple that will be automaticly converted to a ParameterVar type. For examples see Basic Usage.\n\nInitial Condtions generated by Functions\n\nsetup_ic_par_mc_problem(prob::DiffEqBase.DEProblem, ic_gens::Array{<:Function,1}, N_ic::Int, parameters::DEParameters, var_par::ParameterVar)\n\nprob: A Problem from DifferentialEquations, currently supported are DiscreteProblem, ODEProblem, SDEProblem, the base problem one is interested in.\nic_gens: A function or an array of functions that generate the initial conditions for each trial.  Function signature is ()->new_value::Number or (i_run)->new_value::Number. If only one function is provided its used for all IC dims, if MN_dim functions with N_dim=kcdot M are provided these functions are repeated k times (useful e.g. for coupled chaotic oscillators).\nparameters: parameter struct of the underlying system\nvar_par:  ParameterVar, information about how the parameters are varied, see ParameterVar.\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#MCBB.define_new_problem","page":"Problem Types","title":"MCBB.define_new_problem","text":"define_new_problem(prob, ic::Abstract, par::AbstractArray, parameters::DEParameters, N_dim_ic::Int, ic_gens::AbstractArray, var_par::ParameterVar)\n\nReturns the functions that returns new DifferentialEquations problems needed for EnsembleProblem.\n\nprob: A Problem from DifferentialEquations, currently supported are DiscreteProblem, ODEProblem, SDEProblem, DDEProblem the base problem one is interested in.\nic: (N_mc times N_dim_ic)-Matrix containing initial conditions for each run.\npar: (N_mc times N_par)-Matrix containing parameter values for each run.\nN_dim_ic: system dimension\nic_gens: Array of functions or arrays/ranges that contain/generate the ICs.\nvar_par:  ParameterVar, information about how the parameters are varied, see ParameterVar.\n\n\n\n\n\n define_new_problem(prob::CustomProblem, ic_par::AbstractArray, parameters::DEParameters, N_dim_ic::Int, ic_gens::AbstractArray, var_par::ParameterVar)\n\nHelper functions that refurns a function returning new functions needed for CustomMonteCarloProblem.\n\n\n\n\n\n","category":"function"},{"location":"ref/problem_types/#MCBB.tsave_array","page":"Problem Types","title":"MCBB.tsave_array","text":" tsave_array(prob, N_t::Int, rel_transient_time::Float64=0.7)\n\nGiven a tspan to be used in a DEProblem, returns the array/iterator of time points to be saved (saveat argument of solve())\n\nprob: DifferentialEquations problem\nN_t : number of time points to be saved\nrel_transient_time: Only after this time (relative to the total integration time) the solutions are evaluated\n\n\n\n\n\n","category":"function"},{"location":"basic_usage/#Basic-Usage-1","page":"Basic Usage","title":"Basic Usage","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"In the following we will show how the library works on two example, a logistic map and a first order Kuramoto network. All important routines and functions also have docstrings that can be either viewed in the reference here in this documentation or by using Julia's regular help interface (first typing \"?\" and then the name of the function).","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"First, we import the library and all other packages that we need to set up the systems.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"using MCBB\nusing LightGraphs\nusing Clustering\nusing DifferentialEquations\nusing Distributions\nusing StatsBase\nusing Plots\nusing Random\nimport PyPlot\nRandom.Random.seed!(13423);","category":"page"},{"location":"basic_usage/#Logistic-Map-1","page":"Basic Usage","title":"Logistic Map","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"The logistic map x_n+1 = r x_n(1 - x_n) is one of the most well known and studied chaotic systems. Even though this library is tailored towards higher dimensional and multistable system, we can study the logistic map with it as a first example as well.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"First, we set up how the parameter, r and the initial conditions should be varied. The function generating the ICs and parameters need have either ()->new_value::Number or (i_run)->new_value::Number signature.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"rdist = Uniform(2.5,4);\nicdist = Uniform(0.1,0.99);\nr = ()->rand(rdist);\nic_ranges = ()->rand(icdist);","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"There are also other ways to setup the initial conditions. You can define a function that returns an array for all system dimensions for multidimensional systems or provide arrays with the values directly. See DEMCBBProblem for more infos.   Then, we set up how many initial conditons / parameter points we want to generate and solve","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"N_ic = 5000;","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"The parameters of our systems are supposed to be structs whose supertype is DEParameters, e.g. struct my_par <: DEParameters end. In this case, the logistic map and its parameters are already pre-made in the library:","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"pars = logistic_parameters(r());\npar_var = (:r,r);","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"The tuple par_var contains the name of the parameter field to be changed as a symbol and the function how it should be changed. This tuple will be automatically converted to a ParameterVar which also could have been constructed directly. This can be needed for more complicated setups.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"Next, we set up the base DifferentialEquations problem (if you are interested in problems that can't be solved with DifferentialEquations, see CustomMCBBProblem). As mentioned, the logistic map is already one of the pre-made systems, thus","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"dp = DiscreteProblem(logistic, [ic_ranges()], (0.,1000.), pars);","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"We are only interested in solutions after 80% of the integration time","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"tail_frac = 0.8;","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"and can use the pre-made eval_ode_run for analyzing the solutions of each Differential Equation (see eval_ode_run for more information). This eval_ode_run will track the mean, std and Kullback-Leibler divergence of the solutions. Thus we can finally setup the DEMCBBProblem with","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"log_emcp = DEMCBBProblem(dp, ic_ranges, N_ic, pars, (:r,r), eval_ode_run, tail_frac);","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"and solve it","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"log_sol = solve(log_emcp);","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"Subsequently, we calculate the distance matrix and cluster the results","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"D = distance_matrix(log_sol, log_emcp, [1,0.75,0.5,1.]);\n","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"In order to determine the epsilon parameter of DBSCAN we suggest one of three possibilities:","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"k-dist graph to the 4-th Neareast neighbour: k_dist\ncumulative KNN distance: KNN_dist and KNN_dist_relative\nresponse analysis by continuation of the integration (more complicated and computationally intensive): eval_ode_run","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"For many systems we tried, we found that all three methods yield similar results. In this case we take the median of the 05 of all members nearest neighbour (in this case 25-NN).","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"median(KNN_dist_relative(D))\n> 0.06565762359625632","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"db_eps = 0.04\ndb_res = dbscan(D,db_eps,4)\ncluster_members = cluster_membership(log_emcp,db_res,0.005,0.001);\nplot(cluster_members)","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"(Image: Logistic Map Membership Diagram)","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"For more details, see DEMCBBProblem and the other references linked in this section.","category":"page"},{"location":"basic_usage/#Kuramoto-Network-1","page":"Basic Usage","title":"Kuramoto Network","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"Next, we will investigate the onset of synchronization in system of first order Kuramoto oscillators on an Erdos-Renyi random network. We set up the initial conditions and parameters similar to the first example:","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"N = 20\nK = 0.5\nnd = Normal(0.5, 0.1)\nw_i_par = rand(nd,N) # eigenfrequencies\n\nnet = erdos_renyi(N, 0.2)\nA = adjacency_matrix(net)\n\nic = zeros(N)\nic_dist = Uniform(-pi,pi)\nkdist = Uniform(0,5)\nic_ranges = ()->rand(ic_dist)\nN_ics = 5000\nK_range = ()->rand(kdist)\npars = kuramoto_network_parameters(K, w_i_par, N, A)\n\nrp = ODEProblem(kuramoto_network, ic, (0.,1000.), pars)","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"In this case we want to have another evaluation function. We don't need the Kullback-Leibler divergence, but we are interested in the global order parameter as the system to compare it to our results.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"function k_order_parameter(u::AbstractArray)\n    uend = u[:,end]\n    N = length(uend)\n    1. /N*sqrt((sum(sin.(uend)))^2+(sum(cos.(uend)))^2)\nend\n\nfunction eval_ode_run_kura(sol, i)\n    N_dim = length(sol.prob.u0)\n    state_filter = collect(1:N_dim)\n    eval_funcs = [mean, std]\n    matrix_eval_funcs = []\n    global_eval_funcs = [k_order_parameter]\n    eval_ode_run(sol, i, state_filter, eval_funcs, matrix_eval_funcs, global_eval_funcs, cyclic_setback=true)\nend","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"It is also possible to track measures that return matrices or arrays of different size from the 1-d length-N arrays, like cross-correlation or covariance with the matrix_eval_funcs keyword. See eval_ode_run for a detailed reference.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"We set up the DEMCBBProblem again with","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"tail_frac = 0.9  \nko_mcp = DEMCBBProblem(rp, ic_ranges, N_ics, pars, (:K, K_range), eval_ode_run_kura, tail_frac)\nkosol = solve(ko_mcp)","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"and solve and analyze it. In this case we set the weight of the order parameter to zero as we only want to have it as a comparison for our results.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"D_k = distance_matrix(kosol, ko_mcp, [1.,0.5,0,1.], histograms=true, k_bin=2); # no weight on the order_parameter\ndb_eps = 1.15 # we found that value by scanning manually\ndb_res = dbscan(D_k,db_eps,20)\ncluster_members = cluster_membership(ko_mcp,db_res,0.1,0.025);\nplot(cluster_members)","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"(Image: Kuramoto Membership Diagram)","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"In this plot we see the onset of synchronization clearly as three distinctive clusters. We can compare this to the order parameter that we calculated:","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"plot(parameter(ko_mcp),get_measure(kosol,3), xlabel=\"Coupling K\", ylabel=\"Order Parameter R\")","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"(Image: Kuramoto Order Parameter)","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"As we see the cluster membership diagram really shows the onset of the synchronization.","category":"page"},{"location":"basic_usage/#Solution-Object-1","page":"Basic Usage","title":"Solution Object","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"The solution object stores all the measures and some other information. Introspective Features in this manual goes into some more detail about it, but it is important to note that every of the measures are ordered in the following way:     * first: all per dimension measures in the same order as in the eval_funcs array (default: 1: mean, 2: SD, 3: KL-Div)     * then: all matrix measures     * then: all global measures     * optional: for routines that also incorporate the parameters, they are last in order. This order plays a role for all routines that work with one of the measures.","category":"page"},{"location":"basic_usage/#Distance-Matrix/Metric-1","page":"Basic Usage","title":"Distance Matrix/Metric","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"The distance matrix calculation is one of these cases. When we assign the weights in the call to distance matrix, we have to adhere to this ordering. For the example above [1.,0.75,0.,1.] thus means: weight 1. on mean, 0.75 on SD, 0. on KL-Div and 1. on the parameter. The clustering is based on the distance matrix. Its calculation is performed with 'distance_matrix'. Naturally they are many ways how to define a distance matrix between the solutions. They are two main different variants in the library so far","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"Directly compute the difference between the individual values of the measures with a suitable norm. This is the default option (with an L1-norm used)\nFor each measure first compute a histogram or empirical CDF for each run and compare these with each other. For this purpose the keyword histograms=true needs to be set. This is recommended when investigating systems with many (more or less) identical subparts such as oscillator networks and the specific position/number of a single oscillator is not important. The default measure to compare the histograms is the 1-Wasserstein distance.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"The distance functions return elements of type DistanceMatrix or DistanceMatrixHist. They behave just like regular arrays (and are in fact subtypes of AbstractArray) but also hold additional information about how the distance was computed. This can be espacially useful when using the histogram method.","category":"page"},{"location":"basic_usage/#Clustering-1","page":"Basic Usage","title":"Clustering","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"So far, we used mainly DBSCAN for the clustering. In principal, one can also use other clustering algorithms though. DBSCAN also returns a \"Noise Cluster\"/Outlier. In the standard julia implemenation this is Cluster \"0\", here for all routines the Outliers are Cluster \"1\" and all other clusters have the following ascending numbers.","category":"page"},{"location":"basic_usage/#How-to-define-your-own-systems.-1","page":"Basic Usage","title":"How-to define your own systems.","text":"","category":"section"},{"location":"basic_usage/#System-Functions-1","page":"Basic Usage","title":"System Functions","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"The system function follow the notation of DifferentialEquations.jl and should thus have arguments (du,u,p,t) that are changed inplace. For example a Roessler system can be definded with:  ","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"function roessler!(dx,x,p::roessler_pars,t)\n  dx[1] = - x[2] - x[3]\n  dx[2] = x[1] + p.a*x[2]\n  dx[3] = p.b + (x[1] - p.c)*x[3]\nend","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"For more information also see the documentation of DifferentialEquations.jl. In case one wants to work with systems that can't be solved with DifferentialEquations.jl, one has to use CustomMCBBProblem.","category":"page"},{"location":"basic_usage/#Parameters-1","page":"Basic Usage","title":"Parameters","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"All parameters have to have DEParameters as a supertype to work. Thus, for the Roessler example","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"struct roessler_pars <: DEParameters\n  a::Number\n  b::Number\n  c::Number\nend","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"works as the parameter type. See DEParameters and subsequent doc strings for a list of all pre-made functions and parameters.","category":"page"},{"location":"basic_usage/#Varying-hidden/background-parameters-1","page":"Basic Usage","title":"Varying hidden/background parameters","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"It is also possible to investigate setups that have many hidden/background parameters and one/two control parameters. The hidden/background parameters are then treated similar to initial conditions and are randomly generated for each control parameter. See HiddenParameterVar and DEMCBBProblem for more infos.","category":"page"},{"location":"basic_usage/#Saving-and-Loading-1","page":"Basic Usage","title":"Saving & Loading","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"BSON and JLD2 provide easy ways to save and load problem and solutions objects. However sometimes they can be a bit errorprone. If one encounters these kind of errors while loading saved JLD objects, one can also used the save, load_prob and load_sol routines.","category":"page"},{"location":"basic_usage/#Tips-and-Tricks-1","page":"Basic Usage","title":"Tips & Tricks","text":"","category":"section"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"The method relies on random sampling, if you want to share scripts or notebooks and reliably get the same results, you should use a constant seed for the RNG with","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"using Random\nRandom.seed!(23124);","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"This is primarily needed because the ordering of the clusters can change for every run through the script.","category":"page"},{"location":"basic_usage/#","page":"Basic Usage","title":"Basic Usage","text":"In the next section, we will show how these results can be further analyzed.","category":"page"},{"location":"ref/parameter_var/#ParameterVar-1","page":"ParameterVar","title":"ParameterVar","text":"","category":"section"},{"location":"ref/parameter_var/#","page":"ParameterVar","title":"ParameterVar","text":"ParameterVar\nParameterVarArray\nParameterVarFunc\nMultiDimParameterVar\nMCBB.HiddenParameterVar\nBase.getindex(parvar::MultiDimParameterVar, i::Int)\nBase.length(parvar::MultiDimParameterVar)\nParameterVar(prob::myMCProblem)","category":"page"},{"location":"ref/parameter_var/#MCBB.ParameterVar","page":"ParameterVar","title":"MCBB.ParameterVar","text":"ParameterVar\n\nParameter Variation types, these structs holds information about the parameters and how they should be varied. For many cases this struct is automaticlly initialized when calling DEMCBBProblem with appropiate Tuples. It assumes that the parameters are itself structs most commonly with a field that has to be varied.\n\nType Hierachy\n\nOneDimParameterVar, MultiDimParameterVar <: ParameterVar\nParameterVarArray, ParameterVarFunc <: OneDimParameterVar\nMulitDimParameterVarArray, MultiDimParameterVarFunc <: MultiDimParameterVar\n\n\n\n\n\n","category":"type"},{"location":"ref/parameter_var/#MCBB.ParameterVarArray","page":"ParameterVar","title":"MCBB.ParameterVarArray","text":"ParameterVarArray\n\nType for the parameter variation with an array that holds all parameter values. The struct has the fields:\n\nname: Symbol of the name of the parameter\nnew_val:: Function that returns a new value, signature: (i::Int) -> new_value::Number or ()-> new_value::Number\nnew_par:: Function that returns a new parameter struct, default: Parameters.reconstruct, signature: (old_par; Dict(name=>new_val)) = new_par\nN :: Length of the array / Number of parameter values\narr :: The input array saved\n\nInitialization\n\nParameterVar(name::Symbol, arr::AbstractArray, new_par::Function)\nParameterVar(name::Symbol, arr::AbstractArray)\nname is the name of the field of the parameter struct that should be varied\narr is the array that containts all values the parameter should be varied to.\n\n\n\n\n\n","category":"type"},{"location":"ref/parameter_var/#MCBB.ParameterVarFunc","page":"ParameterVar","title":"MCBB.ParameterVarFunc","text":"ParameterVarFunc\n\nStruct for the parameter variation with a function that generates new values. The struct has the fields:\n\nname: Symbol of the name of the parameter\nnew_val:: Function that returns a new value, signature: (i::Int) -> new_value::Number\nnew_par:: Function that returns a new parameter struct, default: Parameters.reconstruct, signature: (old_par; Dict(name=>new_val)) = new_par\n\nInitialization\n\nParameterVar(name::Symbol, func::Function, new_par::Function)\nParameterVar(name::Symbol, func::Function)\nname is the name of the field of the parameter struct that should be varied\nfunc is the function that generates the parameter values, signature: (i::Int) -> new_value::Number\n\n\n\n\n\n","category":"type"},{"location":"ref/parameter_var/#MCBB.MultiDimParameterVar","page":"ParameterVar","title":"MCBB.MultiDimParameterVar","text":"MultiDimParameterVar\n\nHolds information about multiple parameters that should be varied simultaneously. The struct has the fields:\n\ndata: 1-D Array of OneDimParamterVar\nFunction: function that returns a new parameter struct given keyword arguments of all parameters that should be varied. signature: (old_par; Dict(name_1=>new_val_1, name_2=>new_val_2, ...)) = new_par\nN: Number of parameters that are varied.\n\nInternally there are two different main types, MultiDimParameterVarFunc and MultiDimParameterVarArray. The only difference is what type of ParameterVar they store. The different types are needed for dispatching on them in the routines that setups DEMCBBProblem\n\nFor Hidden Parameter Varition (see HiddenParameterVar) there is MultiDimHiddenParameterVar. It always takes the hidden parameters from the first HiddenParameterVar it is initialized with.\n\nInitialization\n\nMultiDimParameterVar(data::Array{ParameterVarFunc,1}, func::Function)\nMultiDimParameterVar(data::Array{ParameterVarArray,1}, func::Function)\nMultiDimParameterVar(parvar::ParameterVar, func::Function)\nMultiDimParameterVar(parvar::ParameterVar): default function is Parameters.reconstruct\n\n\n\n\n\n","category":"type"},{"location":"ref/parameter_var/#MCBB.HiddenParameterVar","page":"ParameterVar","title":"MCBB.HiddenParameterVar","text":"struct HiddenParameterVar <: ParameterVar\n\nSubtype of ParameterVar that varies a lot of \"hidden\"/\"background\" parameters randomly and one control parameter. If multiple control parameters need to varied, MultiDimHiddenParameterVar has to be used.\n\nFields\n\nname::Symbol\npars::AbstractArray stores the values of the hidden parameters\nnew_par::Function function that returns new parameter instance with signature (pars[i,:]..., name=>new_val()) -> new_parameters\nnew_val::Function:: Function that returns new values for the control parameters (i::Int)->new_val::Number\nN_control_par::Int: Number of control parameters drawn/used\nN_hidden_par::Int: Number of 'hidden' parameters\nflag_repeat_hidden_pars::Bool: If true the values pars for the hidden parameters are repeated for every value of the control parameter. If false, then N_control_par==N_hidden_par.\n\nInitialization\n\nHiddenParameterVar(name::Symbol, pars::AbstractArray, new_par::Function, new_val::Function, N_control_par::Int, N_hidden_par::Union{Int, Nothing}=nothing, flag_repeat_hidden_pars::Bool=true)\n\nHiddenParameterVar(name::Symbol, f::Function, new_par, new_val, N_control_par::Int, N_hidden_par::Int, flag_repeat_hidden_pars::Bool=true)\n\n* `f` : Is the function that returns the hidden parameters. Signature `(i)->pars[i,:]` or `()->pars[i,:]`.\n\n\n\n\n\n","category":"type"},{"location":"ref/parameter_var/#Base.getindex-Tuple{MultiDimParameterVar,Int64}","page":"ParameterVar","title":"Base.getindex","text":"getindex(parvar::MultiDimParameterVar, i::Int)\n\nLike regular arrays the individual ParameterVar entries can be accessed with square brackets e.g.: parvar[i].\n\n\n\n\n\n","category":"method"},{"location":"ref/parameter_var/#Base.length-Tuple{MultiDimParameterVar}","page":"ParameterVar","title":"Base.length","text":"length(parvar::MultiDimParameterVar)\n\nLength returns the amount of Parameters that are setup to be varied.\n\n\n\n\n\n","category":"method"},{"location":"ref/parameter_var/#MCBB.ParameterVar-Tuple{myMCProblem}","page":"ParameterVar","title":"MCBB.ParameterVar","text":"ParameterVar(prob::myMCProblem)\n\nGiven one of the problem types of this library its ParameterVar is returned.\n\n\n\n\n\n","category":"method"},{"location":"ref/custom_problem/#Custom-Problem-1","page":"Custom Problems","title":"Custom Problem","text":"","category":"section"},{"location":"ref/custom_problem/#","page":"Custom Problems","title":"Custom Problems","text":"CustomProblem\nsolve(prob::CustomProblem)\nCustomSolution\nsolve(prob::CustomMonteCarloProblem; num_monte::Int, rel_transient_time::Real)\nCustomMonteCarloProblem\nsolve(prob::CustomMCBBProblem)\nCustomMCBBProblem\nCustomMCBBSolution\nnormalize(sol::CustomMCBBSolution, k::AbstractArray)","category":"page"},{"location":"ref/custom_problem/#MCBB.CustomProblem","page":"Custom Problems","title":"MCBB.CustomProblem","text":"CustomProblem\n\nStructure that emulates some of the fields/behaviour of DEProblem subtypes from DifferentialEquations. The results are supposed to be a (Ndim x Nt)-array.\n\nFields:\n\nf: Problem function, signature: (u0, p, tspan) -> results\nu0::AbstractArray: Initial conditions\np: Parameters\ntspan: Time Span\n\n\n\n\n\n","category":"type"},{"location":"ref/custom_problem/#DiffEqBase.solve-Tuple{CustomProblem}","page":"Custom Problems","title":"DiffEqBase.solve","text":"solve(prob::CustomProblem)\n\nSolves/runs the system/experiment with the initial conditions and parameters that were set during construction of prob.\n\n\n\n\n\n","category":"method"},{"location":"ref/custom_problem/#MCBB.CustomSolution","page":"Custom Problems","title":"MCBB.CustomSolution","text":"CustomSolution\n\nSolution type of CustomProblem. Contains the solution as an abstract array and the problem. Can be index like an array.\n\nFields:\n\nsol::AbstractArray: Solution as an Array (1d (N_t-long Array) or 2d (N_dim x N_ts)-sized Array)\nprob::CustomProblem: Problem that was solved to get the solution\n\n\n\n\n\n","category":"type"},{"location":"ref/custom_problem/#DiffEqBase.solve-Tuple{CustomMonteCarloProblem}","page":"Custom Problems","title":"DiffEqBase.solve","text":"solve(prob::CustomMonteCarloProblem; num_monte::Int=100)\n\nSolves the CustomMonteCarloProblem num_monte-times.\n\nTO-DO: parallelization!!!!\n\n\n\n\n\n","category":"method"},{"location":"ref/custom_problem/#MCBB.CustomMonteCarloProblem","page":"Custom Problems","title":"MCBB.CustomMonteCarloProblem","text":"CustomMonteCarloProblem\n\nStructure similar to DifferentialEquations's MonteCarloProblem but for problems that can not be solved with DifferentialEquations. The fields emululate those of EnsembleProblem:\n\nprob::CustomProblem: The base problem that should be solved\nprob_func::Function: same as for EnsembleProblem: A function (prob, i, repeat) -> new_problem that returns the i-th problem that should be solved\neval_func::Function: same as for EnsembleProblem: A function (sol, i) -> (results, repeat) that evaluated the i-th solution\n\n\n\n\n\n","category":"type"},{"location":"ref/custom_problem/#DiffEqBase.solve-Tuple{CustomMCBBProblem}","page":"Custom Problems","title":"DiffEqBase.solve","text":"solve(prob::CustomMCBBProblem)\n\nSolves the CustomMCBBProblem.\n\n\n\n\n\n","category":"method"},{"location":"ref/custom_problem/#MCBB.CustomMCBBProblem","page":"Custom Problems","title":"MCBB.CustomMCBBProblem","text":"CustomMCBBProblem <: MCBBProblem\n\nStructure similar to DEMCBBProblem but for problems that can not be solved with DifferentialEquations as a backend.\n\nNote that its supertypes are MCBBProblem and myMCProblem, but not any of the DifferentialEquations abstract problem types. Many functions that work on DEMCBBProblem work on CustomMCBBProblem as well as they are defined for MCBBProblem.\n\nThe struct has the following fields:\n\np: CustomMonteCarloProblem to be solved, part of DifferentialEquations\nN_mc: Number of (Monte Carlo) runs to be solved\nrel_transient_time: Only after this time (relative to the total integration time) the solutions are evaluated\nic: (N_mc times N_dim_ic)-Matrix containing initial conditions for each run.\npar: (N_mc times N_par)-Matrix containing parameter values for each run.\npar_var: ParameterVar, information about how the parameters are varied, see ParameterVar\n\nConstructors\n\nIt has the same constructors as DEMCBBProblem just with a CustomProblem instead of an DEProblem.\n\n\n\n\n\n","category":"type"},{"location":"ref/custom_problem/#MCBB.CustomMCBBSolution","page":"Custom Problems","title":"MCBB.CustomMCBBSolution","text":"CustomMCBBSolution <: MCBBSol\n\nType that stores the solutions of a CustomMCBBProblem. Is returned by the corresponding solve routine.\n\nIts fields are:\n\nsol: solution of the CustomMonteCarloProblem\nN_mc: number of solutions saved / Monte Carlo trials runs\nN_t: number of time steps for each solutions\nN_dim: sytem dimension\nN_meas: number of measures used, ``N{meas} = N{meas{dim}} + N{meas_{global}}\nN_meas_dim: number of measures that are evalauted for every dimension seperatly\nN_meas_global: number of measures that are evalauted globally\nN_meas_matrix: number of measures that are evalauted globally and return matrices\nsolve_command: A function that solves one individual run/trial with the same settings as where used to, for the CustomProblem type this is trivial (its the field f) but this field is here so that CustomMCBBSolution is compatible with DEMCBBSol\n\nNote, in case N_dim==1 => N_meas_global == 0 and N_meas_dim == N_meas\n\n\n\n\n\n","category":"type"},{"location":"ref/custom_problem/#LinearAlgebra.normalize-Tuple{CustomMCBBSolution,AbstractArray}","page":"Custom Problems","title":"LinearAlgebra.normalize","text":"normalize(sol::CustomMCBBSolution, k::AbstractArray)\n\nReturns a copy of sol with the solutions normalized to be in range [0,1]. It is possible to only select that some of the measures are normalized by providing an array with the indices of the measures that should be normalized, e.g. [1,2] for measure 1 and measure 2 to be normalized.\n\nnormalize(sol::DEMCBBSol)\n\nIf no extra array is provided, all measures are normalized.\n\n\n\n\n\n","category":"method"},{"location":"multidim_parameters/#Multidimensional-Parameter-Setups-1","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"","category":"section"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"Here, we demonstrate the capabilities of setting up systems with multiple parameters. In this case we investigate 15 first Kuramoto oscillators with their eigenfrequencies normally distributed by mathcalN(05sigma) coupled with strength K on a Erdos Renyi random network. In this experiment, we increase sigma and K.","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"using Pkg\nusing MCBB\n\nusing LightGraphs\nusing Clustering\nusing DifferentialEquations\nusing Distributions\nusing StatsBase\nusing PyPlot","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"N = 15\nK = 0.5\nnd = Normal(0.5, 0.2)\nw_i_par = rand(nd,N)\n\nnet = erdos_renyi(N, 0.25)\nA = adjacency_matrix(net)\n\nic = zeros(N)\nic_dist = Uniform(-pi,pi)\nkdist = Uniform(0,5)\nic_ranges = ()->rand(ic_dist)\nN_ics = 10000\nK_range = (i)->rand(kdist)\nstd_range = (i)->rand(Uniform(0.0,0.75))\n\nnew_kura_par(old_par; K=1, std=0.2) = kuramoto_network_parameters(K, rand(Normal(0.5, std), N), N, A)\npar_var = MultiDimParameterVar([OneDimParameterVar(:K,K_range),OneDimParameterVar(:std,std_range)], new_kura_par)    \n\npars = kuramoto_network_parameters(K, w_i_par, N, A)\n\n# base problem\nrp = ODEProblem(kuramoto_network, ic, (0.,3000.), pars)\n\n# we also calculate the order parameter, we won't use it for clustering, but we'll use it as a check\nfunction k_order_parameter(u::AbstractArray)\n    uend = u[:,end]\n    N = length(uend)\n    1. /N*sqrt((sum(sin.(uend)))^2+(sum(cos.(uend)))^2)\nend\n\nfunction eval_ode_run_kura(sol, i)\n    (N_dim, __) = size(sol)\n    state_filter = collect(1:N_dim)\n    eval_funcs = [mean, std]\n    eval_ode_run(sol, i, state_filter, eval_funcs, cyclic_setback=true)\nend\n\ntail_frac = 0.9 #\nko_mcp = DEMCBBProblem(rp, ic_ranges, N_ics, pars, par_var, eval_ode_run_kura, tail_frac)\nkosol = solve(ko_mcp)","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"For multi-parameter setups we need to initialize a instance of MultiDimParameterVar manually and define a suitable function that returns new parameter instances, in this case new_kura_par. For evaluating the results","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"D_k = distance_matrix(kosol, ko_mcp, [1,0.5,1.,1.]); # no weight on the order_parameter and kl div","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"db_eps = 110 # we found that value by scanning manually\ndb_res = dbscan(D_k,db_eps,4)\ncluster_members = cluster_membership(ko_mcp,db_res,[0.5,0.05],[0.2,0.05]);","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"ax = subplot(111)\nplot_surface(cluster_members[1][:,:,1],cluster_members[1][:,:,2],cluster_members[2][:,:,2],alpha=0.5,antialiased=false,color=\"red\")\nplot_surface(cluster_members[1][:,:,1],cluster_members[1][:,:,2],cluster_members[2][:,:,1],alpha=0.5,antialiased=false,color=\"blue\")\nxlabel(\"Coupling K\")\nylabel(\"Std of Eigenfrequencies\")\nzlabel(\"rel. Cluster Membership\")\ntitle(\"Kuramoto Network\")","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"(Image: png)","category":"page"},{"location":"multidim_parameters/#Compare-to-R-1","page":"Multidimensional Parameter Setups","title":"Compare to R","text":"","category":"section"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"par_mesh, Rslid = measure_on_parameter_sliding_window(ko_mcp, kosol, 4, [0.5,0.05],[0.2,0.05]);","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"ax = subplot(111)\nplot_surface(par_mesh[1,:,:],par_mesh[2,:,:],Rslid[1,1,:,:],alpha=0.5,antialiased=false,color=\"red\")","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"(Image: png)","category":"page"},{"location":"multidim_parameters/#","page":"Multidimensional Parameter Setups","title":"Multidimensional Parameter Setups","text":"For further analysis cluster_measures is also working with multiple parameters. ClusterICSpaces does not work (yet) with multiple parameter setups.","category":"page"},{"location":"hpc/#Running-it-on-a-HPC-1","page":"Running it on a HPC","title":"Running it on a HPC","text":"","category":"section"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"The heavy-lifting in terms of parallelization is done by MonteCarloProblem/solve from DifferentialEquations, however we have to make most parts of the setup known to all processes with @everywhere and have a submit script.","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"Below, you will find an example of a script running a Kuramoto network and saving the results. Typically, (due to memory constraints) I would recommend to only solve the DEMCBBProblem on the HPC, then save the solutions and do the remaining calculations (distance matrix and clustering) on your own PC.","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"For saving and loading data, I used JLD2. It needs all functions and variables in scope while loading objects that were used during the computation of the object. That's why I work with only one script that is used on both the remote and local, depending on whether the variable cluster is true or false.","category":"page"},{"location":"hpc/#Julia-Script-(hpc_example.jl)-1","page":"Running it on a HPC","title":"Julia Script (hpc_example.jl)","text":"","category":"section"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"The Julia script is similar to the examples shown in the other guides in this documentation. Running Julia code in parallel on a HPC needs the ClusterManagers package to add the processes that are allocated by the regular Slurm script. If you are running this in parallel without a batch system, change addprocs(ClusterManagers(...)) to addprocs(...).","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"For usage on the HPC set cluster=true\nFor usage on your PC (to evaluate the results) set cluster=false","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"The script needs to be called with an command line argument that specifies the amount of processes that should be initiated, e.g.","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"$ julia hpc_example.jl 4","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"for starting it with 4 processes. In the SLURM script this is done with the environment variable SLURM_NTASKS.","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"DISCLAIMER: In theory, not all of these @everywhere-commands should be needed, but somehow it was not working for me without them. The scripts below are tested on a HPC running SLURM for resource allocation.","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"cluster = true\nusing Distributed\n\nif cluster\n    using ClusterManagers\n    N_tasks = parse(Int, ARGS[1])\n    N_worker = N_tasks\n    addprocs(SlurmManager(N_worker))\nelse\n    using Plots\nend\nusing JLD2, FileIO, Clustering, StatsBase, Parameters\n\n@everywhere begin\n    using LightGraphs\n    using DifferentialEquations\n    using Distributions\n    using MCBB\n\n    N = 40\n    K = 0.5\n    nd = Normal(0.5, 0.1) # distribution for eigenfrequencies # mean = 0.5Hz, std = 0.1Hz\n    w_i_par = rand(nd,N)\n\n    net = erdos_renyi(N, 0.2)\n    A = adjacency_matrix(net)\n\n    ic = zeros(N)\n    ic_dist = Uniform(-pi,pi)\n    kdist = Uniform(0,8)\n    ic_ranges = ()->rand(ic_dist)\n    N_ics = 10000\n    K_range = ()->rand(kdist)\n    pars = kuramoto_network_parameters(K, w_i_par, N, A)\n    rp = ODEProblem(kuramoto_network, ic, (0.,2000.), pars)\n\n    tail_frac = 0.9\nend\n\n@everywhere function eval_ode_run_kuramoto(sol, i)\n    (N_dim, __) = size(sol)\n    state_filter = collect(1:N)\n    eval_funcs = [empirical_1D_KL_divergence_hist]\n    global_eval_funcs = []\n    eval_ode_run(sol, i, state_filter, eval_funcs, global_eval_funcs, cyclic_setback=true)\nend\n\nif cluster\n    ko_mcp = DEMCBBProblem(rp, ic_ranges, N_ics, pars, (:K, K_range), eval_ode_run_kuramoto, tail_frac)\n    kosol = solve(ko_mcp)\n    @save \"kuramoto_sol.jld2\" kosol ko_mcp\nelse\n    @load \"kuramoto_sol.jld2\" kosol ko_mcp\n\n    D = @time distance_matrix(kosol, parameter(ko_mcp), [1,0.75,0.5,1]);\n    k = 4\n    db_eps = median((KNN_dist_relative(D)))\n    db_res = dbscan(D,db_eps,k)\n    cluster_members = cluster_membership(ko_mcp,db_res,0.2,0.05);\n\n    plot(cluster_members)\n    savefig(\"kura-membership\")\nend","category":"page"},{"location":"hpc/#Slurm-Script-1","page":"Running it on a HPC","title":"Slurm Script","text":"","category":"section"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"#!/bin/bash\n\n#SBATCH --qos=short\n#SBATCH --job-name=MCBB-test\n#SBATCH --account=YOURACCOUNT\n#SBATCH --output=MCBB-test-%j-%N.out\n#SBATCH --error=MCBB-test-%j-%N.err\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=8\n#SBATCH --workdir=YOUR/WORK/DIR\n#SBATCH --mail-type=END\n#SBATCH --mail-user=YOUR@MAIL.ADDRESS\n\necho \"------------------------------------------------------------\"\necho \"SLURM JOB ID: $SLURM_JOBID\"\necho \"$SLURM_NTASKS tasks\"\necho \"------------------------------------------------------------\"\n\nmodule load julia/1.0.2\nmodule load hpc/2015\njulia /path/to/the/script/hpc_example.jl $SLURM_NTASKS","category":"page"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"The module load ... commands are for loading julia on the HPC that I use, there might be different kind of setups for your HPC.","category":"page"},{"location":"hpc/#Various-Tips-and-Tricks-1","page":"Running it on a HPC","title":"Various Tips & Tricks","text":"","category":"section"},{"location":"hpc/#","page":"Running it on a HPC","title":"Running it on a HPC","text":"At least on some HPCs such a script can fail after any julia library updates when the packages are not precompiled yet. Just run the script again or force a precompilation from an interactive session.","category":"page"},{"location":"ref/systems/#Pre-Made-Systems-and-Parameters-1","page":"Systems","title":"Pre-Made Systems and Parameters","text":"","category":"section"},{"location":"ref/systems/#","page":"Systems","title":"Systems","text":"There will be a list of all pre-made systems and parameters here.","category":"page"},{"location":"ref/systems/#","page":"Systems","title":"Systems","text":"DEParameters\nlogistic\nlogistic_parameters\nhenon\nhenon_parameters\nkuramoto\nkuramoto_parameters\nkuramoto_network\nkuramoto_network_parameters\nsecond_order_kuramoto\nsecond_order_kuramoto_parameters\nsecond_order_kuramoto_chain\nsecond_order_kuramoto_chain_parameters\nnon_local_kuramoto_ring\nnon_local_kuramoto_ring_parameters\norder_parameter\nroessler_parameters\nroessler_network","category":"page"},{"location":"ref/systems/#MCBB.DEParameters","page":"Systems","title":"MCBB.DEParameters","text":"DEParameters\n\nAbstract type for all parameter types. If you define your own systems the parameters have to have this as a supertype.\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.logistic","page":"Systems","title":"MCBB.logistic","text":"logistic(u_next, u, p::logistic_parameters, t)\n\nLogistic Map: x_n+1 = rx_n (1 - x_n)\n\n\n\n\n\n","category":"function"},{"location":"ref/systems/#MCBB.logistic_parameters","page":"Systems","title":"MCBB.logistic_parameters","text":" logistic_parameters\n\nParameters of the logistic map. Its function is logistic.\n\nFields: *r::Float64\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.henon","page":"Systems","title":"MCBB.henon","text":"henon(u_next, u, p::henon_parameters, t)\n\nHenon map. x_n+1 = 1 - a x_n^2 + y_n y_n+1 = b x_n\n\n\n\n\n\n","category":"function"},{"location":"ref/systems/#MCBB.henon_parameters","page":"Systems","title":"MCBB.henon_parameters","text":"henon_parameters\n\nParameters of the Henon map. Its function is henon.\n\nFields: *a::Float64 *b::Float64\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.kuramoto","page":"Systems","title":"MCBB.kuramoto","text":"kuramoto(du, u, p::kuramoto_parameters, t)\n\nFirst order Kuramoto system with all-to-all coupling. dottheta_i = w_i + KN sum_i sin(theta_j - theta_i)\n\n\n\n\n\n","category":"function"},{"location":"ref/systems/#MCBB.kuramoto_parameters","page":"Systems","title":"MCBB.kuramoto_parameters","text":"kuramoto_parameters\n\nParameters of a first order Kuramoto system with all-to-all coupling. Fields:\n\nK::Number: Coupling Strength\nw::Array{Float64}: Eigenfrequencies\nN::Int: Number of Oscillators\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.kuramoto_network","page":"Systems","title":"MCBB.kuramoto_network","text":"kuramoto_network(du, u, p::kuramoto_parameters, t)\n\nFirst order Kuramoto system on a network. dottheta_i = w_i + KN sum_i A_ijsin(theta_j - theta_i)\n\n\n\n\n\n","category":"function"},{"location":"ref/systems/#MCBB.kuramoto_network_parameters","page":"Systems","title":"MCBB.kuramoto_network_parameters","text":"kuramoto_network_parameters\n\nParameters of a first order Kuramoto system on a network. Fields:\n\nK::Number: Coupling Strength\nw::Array{Float64}: Eigenfrequencies\nN::Int: Number of Oscillators\nA: Adjacency matrix\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.second_order_kuramoto","page":"Systems","title":"MCBB.second_order_kuramoto","text":"second_order_kuramoto(du, u, p::second_order_kuramoto_parameters, t)\n\nSecond order Kuramoto system on the adjacency matrix A_ij = E_ie E_ej.\n\ndottheta_i = w_i dotomega = Omega_i - alphaomega + lambdasum_j=1^N A_ij sin(theta_j - theta_i)\n\n\n\n\n\n","category":"function"},{"location":"ref/systems/#MCBB.second_order_kuramoto_parameters","page":"Systems","title":"MCBB.second_order_kuramoto_parameters","text":"second_order_kuramoto_parameters\n\nFields:\n\nsystemsize::Int, number of oscillators\ndamping::Float64, Damping, also referred to as alpha\ncoupling::Float64, Coupling strength, also referred to as lambda\nincidence, oriented incidence matix of the network, also referred to as E_ei\n\nindicating if a vertex i belongs to an edge e. Following the conventions of LightGraphs\n\ndrive::Array{Float64}, external driving, also referred to as Omega\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.second_order_kuramoto_chain","page":"Systems","title":"MCBB.second_order_kuramoto_chain","text":"second_order_kuramoto_chain(du, u, p::kuramoto_parameters, t)\n\nSecond order Kuramoto system on a chain.\n\ndottheta_i = w_i dotomega = Omega_i - alphaomega + lambdasum_j=1^N A_ij sin(theta_j - theta_i)\n\nA_ij = 1 if and only if i-j=1, otherwise A_ij=0\n\n\n\n\n\n","category":"function"},{"location":"ref/systems/#MCBB.second_order_kuramoto_chain_parameters","page":"Systems","title":"MCBB.second_order_kuramoto_chain_parameters","text":"second_order_kuramoto_chain_parameters\n\nFields:\n\nsystemsize::Int, number of oscillators\ndamping::Float64, Damping, also referred to as alpha\ncoupling::Float64, Coupling strength, also referred to as lambda\ndrive::Array{Float64}, external driving, also referred to as Omega\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.non_local_kuramoto_ring","page":"Systems","title":"MCBB.non_local_kuramoto_ring","text":"non_local_kuramoto_ring(du, u, p::non_local_kuramoto_ring_parameters, t)\n\nFirst order Kuramoto oscillators on a ring with non-local coupling.\n\nfractheta_kdt = omega_0 - sum_j=1^N G_1left(frac2piN(k-j)right)sinleft(theta_k(t) - theta_j(k) + alpharight)\n\n\n\n\n\n","category":"function"},{"location":"ref/systems/#MCBB.non_local_kuramoto_ring_parameters","page":"Systems","title":"MCBB.non_local_kuramoto_ring_parameters","text":"non_local_kuramoto_ring_parameters <: DEParameters\n\nN::Integer: Number of Oscillators\nfak::Float64: frac2pin\nomega_0::Number: eigenfrequency of all oscillators\nphase_delay: Phase Delay alpha\ncoupling_function: Coupling function G(x), signature (x::Number)-> value::Number\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.order_parameter","page":"Systems","title":"MCBB.order_parameter","text":"order_parameter(u::AbstractArray, N::Int)\n\nOrder Parameter of a Kuramoto System\n\n\n\n\n\n","category":"function"},{"location":"ref/systems/#MCBB.roessler_parameters","page":"Systems","title":"MCBB.roessler_parameters","text":"roessler_parameters <: DEParameters\n\nParameters of a Roessler network\n\na::Array{Float64}: a Parameters of all oscillators.\nb::Array{Float64}: b Parameters of all oscillators.\nc::Array{Float64}: c Parameters of all oscillators.\nK::Float64: Coupling Strength\nL::Array{Float64}: Laplacian matrix of the network\nN::Int: Number of nodes/oscilattors\nroessler_parameters(a, b, c, K, k::Int64, p::Float64, N)\n\nGenerates a set of roessler_parameters with a Watts Strogatz random Network with mean degreee k and rewiring probability p\n\n\n\n\n\n","category":"type"},{"location":"ref/systems/#MCBB.roessler_network","page":"Systems","title":"MCBB.roessler_network","text":"roessler_network(du, u, p::roessler_parameters, t)\n\nN Roessler Parameters coupled on their x-component\n\n\n\n\n\n","category":"function"},{"location":"introspective_features/#Introspective-Features-1","page":"Introspective Features","title":"Introspective Features","text":"","category":"section"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"This page showcases introspective features of the libary.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"The example are First Order Kuramoto Oscillators with mathcalN(0501) distributed eigenfrequencies on a Erdos Renyi random network. Subsequently the coupling is increased as the free parameter. The basic setup is identical to the previous section.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"using MCBB\nusing LightGraphs\nusing Clustering\nusing DifferentialEquations\nusing Distributions\nusing StatsBase\nusing Plots\nusing Random\nimport PyPlot\nRandom.Random.seed!(13423);","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"N = 20\nK = 0.5\nnd = Normal(0.5, 0.1)\nw_i_par = rand(nd,N) # eigenfrequencies\n\nnet = erdos_renyi(N, 0.2)\nA = adjacency_matrix(net)\n\nic = zeros(N)\nic_dist = Uniform(-pi,pi)\nkdist = Uniform(0,5)\nic_ranges = ()->rand(ic_dist)\nN_ics = 5000\nK_range = ()->rand(kdist)\npars = kuramoto_network_parameters(K, w_i_par, N, A)\n\nrp = ODEProblem(kuramoto_network, ic, (0.,1000.), pars)\n\n# we also calculate the order parameter, we won't use it for clustering, but we'll use it as a check\nfunction k_order_parameter(u::AbstractArray)\n    uend = u[:,end]\n    N = length(uend)\n    1. /N*sqrt((sum(sin.(uend)))^2+(sum(cos.(uend)))^2)\nend\n\nfunction eval_ode_run_kura(sol, i)\n    N_dim = length(sol.prob.u0)\n    state_filter = collect(1:N_dim)\n    eval_funcs = [mean, std]\n    matrix_eval_funcs = []\n    global_eval_funcs = [k_order_parameter]\n    eval_ode_run(sol, i, state_filter, eval_funcs, matrix_eval_funcs, global_eval_funcs, cyclic_setback=true)\nend\n\ntail_frac = 0.9 #\nko_mcp = DEMCBBProblem(rp, ic_ranges, N_ics, pars, (:K, K_range), eval_ode_run_kura, tail_frac)\nkosol = solve(ko_mcp)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"The results are sorted by parameter value, show_results shows only results within the given parameter range.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"normalize(sol:DEMCBBSol) normalized the results so that all measures are within the range 01.","category":"page"},{"location":"introspective_features/#Cluster-Membership-1","page":"Introspective Features","title":"Cluster Membership","text":"","category":"section"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"D_k = distance_matrix(kosol, ko_mcp, [1.,0.5,0,1.], histograms=true, k_bin=2); # no weight on the order_parameter db_eps = 110 # we found that value by scanning manually\ndb_eps = 1.15# we found that value by scanning manually\ndb_res = dbscan(D_k,db_eps,20)\ncluster_members = cluster_membership(ko_mcp,db_res,0.1,0.025);\nplot(cluster_members)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramato Membership Diagram)","category":"page"},{"location":"introspective_features/#Plot-Measures-1","page":"Introspective Features","title":"Plot Measures","text":"","category":"section"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"plot one of the measures dependend on the parameter with get_measure gets the k-th measure. In this case the order is [mean, std, kl-div, order parameter]\nget the parameter array with parameter(prob::BifMCProblem)\nhere we plot the Order Parameter","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"plot(parameter(ko_mcp),get_measure(kosol,3), xlabel=\"Coupling K\", ylabel=\"Order Parameter R\")","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramaoto Order Parameter)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"Or do this with a sliding window:","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"p_wins, R_grid = measure_on_parameter_sliding_window(ko_mcp, kosol, 3, 0.2, 0.025);\nplot(p_wins,R_grid[1,1,:], xlabel=\"Coupling K\", ylabel=\"Order Parameter R\",title=\"Slding Window Order Parameter\")","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Order Parameter Sliding Window)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"Of course we can also get the multidimensional measures","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"plot(parameter(ko_mcp),get_measure(kosol,1), xlabel=\"Coupling K\", ylabel=\"Mean\")","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Mean)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"In this plot we already see the onset of the synchronization.","category":"page"},{"location":"introspective_features/#Cluster-Measures-1","page":"Introspective Features","title":"Cluster Measures","text":"","category":"section"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"We can restrict this analysis to single clusters as well.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"With the methods 'clustermeasuremean' and 'clustermeasurestd' get the means and stds of selected measures seperatly for each cluster. We can plot these with an errorbar plot to get an intuition into typical values of these measures for each cluster and how they differ from each other.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"colororder = [\"blue\",\"orange\",\"green\",\"red\",\"purple\",\"brown\",\"magenta\",\"olive\",\"cyan\"]\nmeasure_1 = 1\nmeasure_2 = 2\n\nm1m = cluster_measure_mean(kosol, db_res, measure_1)\nm1sd = cluster_measure_std(kosol, db_res, measure_1)\nm2m = cluster_measure_mean(kosol, db_res, measure_2)\nm2sd = cluster_measure_std(kosol, db_res, measure_2)\n\nSC = PyPlot.scatter(m1m, m2m, c=colororder[1:length(m1m)])\nPyPlot.errorbar(m1m, m2m, fmt=\"o\", ms=0,ecolor=colororder, xerr=0.005*m1sd, yerr=0.1*m2sd)\nPyPlot.xlabel(\"Average Mean\")\nPyPlot.ylabel(\"Average Std\")\nPyPlot.savefig(\"output_msk.png\")","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Cluster Means and Stds)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"In this case we scaled the error bars, as the Stds of the measures is much larger than the differences in the Average meausres. This is due to the fact that the Kuramoto oscillators are all oscillating relativly fast in this setup. It is important to note that for Cluster 3, the synchronous state, the Stds have a very small Std, meaning that almost all trials in this cluster have the same Std. This is clearly a strong indicator for a synchronous state. Cluster 2 and the noise cluster have only a slightly different average mean and std, if one would decrease the DBSCAN \\epsilon parameter, they would probably be classified as only one cluster.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"The method cluster_measures gets the measure for each cluster seperately and applies a sliding window. The routine returns the parameter values of the sliding window, a N_clustertimes N_measurestimes N_dimtimes N_windows array for measures that are evalauted for every dimension and a N_clustertimes N_measurestimes N_windows for global measures. For windows in which the cluster has no members a NaN is returned. This is (in constrast to missing or nothing) compatible with most plotting routines. We should however always define common x-Limits for the plots because of this. It returns these within a ClusterMeasureResult struct that can be plotted easily, as they are plot recipes defined.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"cluster_meas_res = cluster_measures(ko_mcp, kosol, db_res, 0.1, 0.01);","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"xlim_values = [0, 5]\nplot(cluster_meas_res, 1, 1, xlims=xlim_values, title=\"Means Cluster 1\", xlabel=\"Coupling K\")","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Cluster 1 Means)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"plot(cluster_meas_res, 1, 2, xlims=xlim_values, title=\"Means Cluster 2\", xlabel=\"Coupling K\")","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Cluster 2 Means)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"plot(cluster_meas_res, 1, 3, xlims=xlim_values, title=\"Means Cluster 3\", xlabel=\"Coupling K\")","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Cluster 3 Means)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"The method cluster_means returns the mean value of each measure for each cluster.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"cluster_ms = cluster_means(kosol, db_res);\nprint(\"Means of the 3rd cluster: \")\nprint(cluster_ms[3,1,:])","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"Means of the 3rd cluster: [29.4609, 29.4524, 29.4574, 29.4589, 29.4585, 29.4609, 29.4593, 29.4607, 31.5164, 29.4558, 27.5155, 29.4559, 29.4578, 29.4578, 29.4576, 29.4582, 31.7665, 29.4609, 29.4653, 29.595]","category":"page"},{"location":"introspective_features/#Single-Trajectories-1","page":"Introspective Features","title":"Single Trajectories","text":"","category":"section"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"With the method get_trajectory we can get the full trajectory of an example trial within a certain cluster. This can help us get a further impression of the nature of the trajectories inside the cluster.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"IM = PyPlot.imshow(Matrix(get_trajectory(ko_mcp,kosol, db_res, 3,only_sol=true)), aspect=4)\nPyPlot.ylabel(\"Oscillator i\")\nPyPlot.xlabel(\"Time\")\ncb = PyPlot.colorbar(IM, orientation=\"horizontal\")\ncb[:ax][:set_xlabel](\"Colorbar: Im(z)\", rotation=0)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"For the zeroth/Noise cluster we see an unordered system","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Unordered Example)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"and for the second cluster we see a synchronized system (except for one oscillator that is disconnected in this particular random network)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Ordered Example)","category":"page"},{"location":"introspective_features/#Cluster-Measure-Histograms-1","page":"Introspective Features","title":"Cluster Measure Histograms","text":"","category":"section"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"It is also possible to show how the histograms of a measure on a sliding window. cluster_measures_sliding_histograms does just that. It returns for each cluster and for each window a histogram of a measure of your choice as a ClusterMeasureHistogramResult.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"cluster_hist_res = cluster_measures_sliding_histograms(ko_mcp, kosol, db_res, 1, 0.25, 0.125)\nplot(cluster_hist_res, 1)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Cluster 1)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"For the synchronized state the means are in a narrow band and outside of these band they are no values, while for the unordered cluster the means have a broad distribution.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Cluster 2)","category":"page"},{"location":"introspective_features/#Cluster-Initial-Conditions-1","page":"Introspective Features","title":"Cluster Initial Conditions","text":"","category":"section"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"ClusterICSpaces enables us to analyse which initial conditions lead to the different clusters. The struct is constructed with ClusterICSpaces. Additional parameter bounds can be provided to rescrict the analysis to the specified parameter range. It returns the ClusterICSpaces-struct with the fields:","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"data::AbstractArray: Ncluster long Array of Ndim+1 (+1 for the parameter) Arrays with the ICs/Parameter, e.g. data[2][1] for the ICs of IC-dimension 1 that lead to results classified in cluster 2\nhistograms::AbstractArray: Ncluster long array of of Ndim+1 histograms for each IC/Par dimension and Cluster\nmeans::AbstractArray: means of data\nstds::AbstractArray: stds of data","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"Statistics of the ICs across their dimension. For each run the mean, stds, skew of the ICs used for this run is calculated, These are the distributions of theses statistics for all runs. For example certain clusters/behaviour must be favoured if the ICs are already very close together, thus possessing a small std","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"cross_dim_means::AbstractArray\ncross_dim_stds::AbstractArray\ncross_dim_skews::AbstractArray","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"cics = ClusterICSpaces(ko_mcp, kosol, db_res; min_par=1, max_par=4);","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"PyPlot.plt[:hist](cics.cross_dim_stds[1], density=true, alpha=0.5, label=\"Cluster1\")\nPyPlot.plt[:hist](cics.cross_dim_stds[2], density=true, alpha=0.5, label=\"Cluster2\")\nPyPlot.plt[:hist](cics.cross_dim_stds[3], density=true, alpha=0.5, label=\"Cluster3\")\nPyPlot.xlabel(\"Standard Deviation of all ICs in a run\")\nPyPlot.ylabel(\"rel. Magnitude\")\nPyPlot.legend();","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Cross Dim IC)","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"This shows the Stds of the ICs for each Cluster.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"Next we plot the distributions of each IC dimension for each Cluster.","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"ICPlot = 1:6 # which IC dimensions to plot\ncics_in = cics\ni_cluster = 1 # which cluster to plot\n\nhists = cics_in.histograms[i_cluster]\nnbins = length(hists[1].weights)\nn_dim = length(ICPlot)\nweights = zeros((n_dim,nbins))\nedges = zeros((n_dim,nbins+1))\nfor i=1:n_dim\n    weights[i,:] = hists[ICPlot[i]].weights\n    edges[i,:] = hists[ICPlot[i]].edges[1]\nend\n\nweight_maxima = maximum(weights;dims=2)\nhist_range = [minimum(edges),maximum(edges)]\nmax_weight_maxima = maximum(weight_maxima)\nx_locs = 0:(max_weight_maxima+0.05*max_weight_maxima):(sum(weight_maxima)+max_weight_maxima)\n\ncenters = (edges[:,1:end-1] .+ edges[:,2:end]) ./ 2\nheights = diff(edges, dims=2)\n\nfig, ax = PyPlot.subplots()\n\n\nfor i_hist=1:n_dim\n    ax[:barh](centers[i_hist,:], weights[i_hist,:], height=heights[i_hist,:], left=x_locs[i_hist])\nend\n\nPyPlot.xlabel(\"IC Dimensions\")\nPyPlot.ylabel(\"IC values\")\n\nax[:set_xticks](x_locs)\nax[:set_xticklabels]([string(i) for i in ICPlot]);","category":"page"},{"location":"introspective_features/#","page":"Introspective Features","title":"Introspective Features","text":"(Image: Kuramoto Histograms)","category":"page"},{"location":"continuation/#Continuation-1","page":"Continuation","title":"Continuation","text":"","category":"section"},{"location":"continuation/#","page":"Continuation","title":"Continuation","text":"The library also includes some tools to run a more classical bifurcation analysis by continuing the integration of a system with a changed parameter and the end point of the last integration as the new initial conditions. A detailed how-to will follow, but for now there's also already a reference (ContinuationProblem)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"CurrentModule = MCBB\nDocTestSetup  = quote\n    using MCBB\nend","category":"page"},{"location":"#Idea-1","page":"Home","title":"Idea","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Here, there will be a desciption of the basic idea and aim of the package and a link to the paper describing the method.","category":"page"},{"location":"#Contents-1","page":"Home","title":"Contents","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\"index.md\", \"basic_usage.md\", \"introspective_features.md\", \"hpc.md\",\n    \"multidim_parameters.md\", \"ref/problem_types.md\", \"ref/parameter_var.md\",\n    \"ref/evaluation_funcs.md\", \"ref/clustering_funcs.md\", \"ref/continuation.md\",\n    \"ref/bbclustering.md\", \"ref/systems.md\"]\nDepth = 5","category":"page"},{"location":"ref/continuation/#ContinuationProblem-1","page":"Continuation","title":"ContinuationProblem","text":"","category":"section"},{"location":"ref/continuation/#","page":"Continuation","title":"Continuation","text":"ContinuationProblem","category":"page"},{"location":"ref/continuation/#MCBB.ContinuationProblem","page":"Continuation","title":"MCBB.ContinuationProblem","text":"ContinuationProblem <: myMCProblem\n\nIntroduces a Problem type for Bifurcation analysis. It sets up a DEProblem, solves it, then changes a parameter and sets the endpoint of the previous to be IC of a new problem. Repeats for a specified amount of times\n\nConstructor\n\nContinuationProblem(p::DiffEqBase.DEProblem, par_range::ParameterVar, N::Int64, eval_func::Function, ic_bounds::AbstractArray=[-Inf,Inf],par_bounds::AbstractArray=[-Inf,Inf], hard_bounds::Bool=false)\n\np: Base DifferentialEquations Problem\npar_range: Description of how the parameter should be changed, ParameterVar OR a tuple of (First: name of the parameter as a symbol, Second: AbstractArray or Function that contains all parameters for the experiment or a function that generates parameter values. The function has to be format (oldvalue) -> (newvalue), Third: OPTIONAL: a function that maps (old_parameter_instance; (par_range[1],new_parameter_value)) -> new_parameter_instance. Default is 'reconstruct' from @with_kw/Parameters.jl is used)\nN: OPTIONAL, Only needed if parameter variation is given a function to generate new parameter values. If so, N is the total number of parameters and thus DEProblems to be solved\neval_ode_run: function, same as for EnsembleProblems\nic_bounds: Bounds for the IC that should not be exceeded\npar_bounds: Bounds for the parameter that should not be exceeded\nhard_bounds: If a bound is reached: if true, stops the iteration, false continous with (upper/lower bound as IC)\n\nFields of the struct are the same as the arguments of the constructor.\n\n\n\n\n\n","category":"type"},{"location":"ref/continuation/#","page":"Continuation","title":"Continuation","text":"ContinuationSolution","category":"page"},{"location":"ref/continuation/#MCBB.ContinuationSolution","page":"Continuation","title":"MCBB.ContinuationSolution","text":"ContinuationSolution <: myMCSol\n\nSolution object that is returned by solve(prob::ContinuationProblem,...).\n\nFields are:\n\nsol: Array of Arrays, analogously to EnsembleSolution\npar: Array, parameters of all runs\nN_mc: Number of runs / DEProblems solved\nN_meas: number of measures used, N_meas = N_meas_dim + N_meas_global\nN_meas_dim: number of measures that are evalauted for every dimension seperatly\nN_meas_global: number of measures that are evalauted globally\nN_meas_matrix: number of measures that return matrices.\n\n\n\n\n\n","category":"type"},{"location":"ref/continuation/#","page":"Continuation","title":"Continuation","text":"compute_parameters","category":"page"},{"location":"ref/continuation/#MCBB.compute_parameters","page":"Continuation","title":"MCBB.compute_parameters","text":"compute_parameters(p::DiffEqBase.DEProblem , par_range::OneDimParameterVar, N::Integer)\n\nComputes the parameters that are used for the calculation and returns them as an array.\n\n\n\n\n\n","category":"function"},{"location":"ref/continuation/#","page":"Continuation","title":"Continuation","text":"solve(prob::ContinuationProblem, N_t=400::Int, rel_transient_time::Float64=0.9; return_probs::Bool=false, reltol::Float64=1e-9, cyclic_ic::Bool=false, kwargs...)","category":"page"},{"location":"ref/continuation/#DiffEqBase.solve","page":"Continuation","title":"DiffEqBase.solve","text":" solve(prob::ContinuationProblem, N_t=400::Int, rel_transient_time::Float64=0.9; return_probs::Bool=false, reltol::Float64=1e-9, cyclic_ic::Bool=false, kwargs...)\n\nCustom solve for the ContinuationProblem. Saves and evaluates only after transient at a constant step size.\n\nN_t - Int, Number of timesteps of each solution of a DEProblem\nrel_transient_time - Percentage of time after which the solutions are evaluated\nreturn_probs - if 'true' returns a array of DEProblems that were solved\nreltol - relative tolerance of the solver.Eespacially for systems with constantly growing variables such as certain phase oscilattors the tolerence has to be very small\ncyclic_ic - if true the initial conditions are always within -pipi\n\n\n\n\n\n","category":"function"}]
}
